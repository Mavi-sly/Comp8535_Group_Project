{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db60baf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1db60baf",
    "outputId": "9c1aafab-ba38-4860-a13e-8492682a06fb"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "mbti_df = pd.read_csv('mbti_1.csv')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUML_LOG_LEVEL\"] = \"ERROR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d43947",
   "metadata": {
    "id": "00d43947"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/meitongliu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/meitongliu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# data preprocess\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 1. Text normalization\n",
    "# (i) convert to lowercase;\n",
    "# (ii) remove url;\n",
    "# (iii) remove numbers;\n",
    "# (iv) remove non-alphanumeric characters (punctuation, special characters);\n",
    "# (v) remove underscores and signs;\n",
    "# (vi) replace multiple spaces with single spaces;\n",
    "# (vii) remove stopwords;\n",
    "# (viii) remove one-letter words;\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    pattern = re.compile(r'https?://[a-zA-Z0-9./-]*/[a-zA-Z0-9?=_.]*[_0-9.a-zA-Z/-]*')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    pattern = re.compile(r'[0-9]')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    pattern = re.compile(r'[_+]')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text).strip()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    text = \" \".join([w for w in text.split() if w not in stop_words])\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 1])\n",
    "    return text\n",
    "\n",
    "# 2. Lemmatization\n",
    "# (i) use NLTK's lemmatizer\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "# 3. Select classification dimension (16-class classification or binary classification on single dimension)\n",
    "def select_classification_dimension(df, num=0):\n",
    "    if num == 16:\n",
    "        return df['type']\n",
    "    elif 1 <= num <= 4:\n",
    "        return df['type'].str[num-1]\n",
    "    else:\n",
    "        print(\"selection error of classification dimension!\")\n",
    "        return df['type']\n",
    "\n",
    "# 4. Label encoding\n",
    "# (i) creates an array corresponding to the type labels.\n",
    "def encode_labels(column):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(column)\n",
    "    mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "    print(f\"Label encoding mapping: {mapping}\")\n",
    "    print(f\"Encoded label examples: {y[:5]}\")\n",
    "    print(f\"Unique encoded labels: {np.unique(y)}\")\n",
    "    return y, le\n",
    "\n",
    "mbti_df[\"posts\"] = mbti_df[\"posts\"].str.lower()       #converts text in posts to lowercase as it is preferred in nlp\n",
    "\n",
    "for i in range(len(mbti_df)):\n",
    "  post_temp=mbti_df._get_value(i, 'posts')\n",
    "  pattern = re.compile(r'https?://[a-zA-Z0-9./-]*/[a-zA-Z0-9?=_.]*[_0-9.a-zA-Z/-]*')    #to match url links present in the post\n",
    "  post_temp= re.sub(pattern, ' ', post_temp)                                            #to replace that url link with space\n",
    "  mbti_df._set_value(i, 'posts',post_temp)\n",
    "\n",
    "for i in range(len(mbti_df)):\n",
    "  post_temp=mbti_df._get_value(i, 'posts')\n",
    "  pattern = re.compile(r'[0-9]')                                    #to match numbers from 0 to 9\n",
    "  post_temp= re.sub(pattern, ' ', post_temp)                        #to replace them with space\n",
    "  pattern = re.compile('\\W+')                                       #to match alphanumeric characters\n",
    "  post_temp= re.sub(pattern, ' ', post_temp)                        #to replace them with space\n",
    "  pattern = re.compile(r'[_+]')\n",
    "  post_temp= re.sub(pattern, ' ', post_temp)\n",
    "  mbti_df._set_value(i, 'posts',post_temp)\n",
    "\n",
    "for i in range(len(mbti_df)):\n",
    "  post_temp=mbti_df._get_value(i, 'posts')\n",
    "  pattern = re.compile('\\s+')                                     #to match multiple whitespaces\n",
    "  post_temp= re.sub(pattern, ' ', post_temp)                      #to replace them with single whitespace\n",
    "  mbti_df._set_value(i, 'posts', post_temp)\n",
    "remove_words = stopwords.words(\"english\")                         # remove stopwords\n",
    "for i in range(mbti_df.shape[0]):\n",
    "  post_temp=mbti_df._get_value(i, 'posts')\n",
    "  post_temp=\" \".join([w for w in post_temp.split(' ') if w not in remove_words])    #to remove stopwords\n",
    "  mbti_df._set_value(i, 'posts', post_temp)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(mbti_df.shape[0]):\n",
    "  post_temp=mbti_df._get_value(i, 'posts')\n",
    "  post_temp=\" \".join([lemmatizer.lemmatize(w) for w in post_temp.split(' ')])   #to implement lemmetization i.e. to group together different forms of a word\n",
    "  mbti_df._set_value(i, 'posts', post_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f00092",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3f00092",
    "outputId": "a57f0672-9d64-444f-d3dd-8dd1ac8f11e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      type                                              posts\n",
      "7814  INFP   macona depends big family extroverted people ...\n",
      "2233  ENFJ   blodsmak sveltihel brilliant episode regenera...\n",
      "7261  INFJ   heylena lol compliment accepted thank jeesh f...\n",
      "7794  INFJ   pac right rocket coffin like packed warhead r...\n",
      "2950  INTJ   title thread misleading mention world dominat...\n",
      "...    ...                                                ...\n",
      "2006  INTJ   one sentence restrictive accurately portray d...\n",
      "7137  ISTJ   wanted like odd hybrid dr james wilson house ...\n",
      "6091  ENTP   took cognitive process test got cognitive pro...\n",
      "2997  INFJ   get caught fantacy relationship better forget...\n",
      "5458  ENTJ   doll love movie listed make think tritype one...\n",
      "\n",
      "[1735 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data=train_test_split(mbti_df,test_size=0.2,random_state=42,stratify=mbti_df.type)\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0789985d",
   "metadata": {
    "id": "0789985d"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# vectorize the data with TF-IDF\n",
    "\n",
    "vectorizer=TfidfVectorizer( max_features=5000,stop_words='english')\n",
    "vectorizer.fit(train_data.posts)\n",
    "train_post=vectorizer.transform(train_data.posts).toarray()\n",
    "test_post=vectorizer.transform(test_data.posts).toarray()\n",
    "target_encoder=LabelEncoder()\n",
    "train_target=target_encoder.fit_transform(train_data.type)\n",
    "test_target = target_encoder.transform(test_data.type)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84306028",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84306028",
    "outputId": "3cab2b60-33c4-4b01-a7cc-6b4cf0d6af01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/meitongliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/meitongliu/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def extract_stylometric_features(text):\n",
    "    # print(f\"Input text: {text}\")\n",
    "    sentences = sent_tokenize(text)\n",
    "    # print(f\"Split sentences: {sentences}\")\n",
    "    words = word_tokenize(text)\n",
    "    # print(f\"Words: {words}\")\n",
    "    num_sentences = len(sentences)\n",
    "    # print(f\"Number of sentences: {num_sentences}\")\n",
    "    num_words = len(words)\n",
    "    # print(f\"Number of words: {num_words}\")\n",
    "    num_chars = len(text)\n",
    "    # print(f\"Number of characters: {num_chars}\")\n",
    "    num_exclamations = text.count('!')\n",
    "    # print(f\"Number of exclamation marks: {num_exclamations}\")\n",
    "    num_questions = text.count('?')\n",
    "    # print(f\"Number of question marks: {num_questions}\")\n",
    "    num_uppercase_words = sum(1 for w in words if w.isupper())\n",
    "    # print(f\"Number of uppercase words: {num_uppercase_words}\")\n",
    "    lexical_diversity = len(set(words)) / num_words if num_words > 0 else 0\n",
    "    # print(f\"Lexical diversity: {lexical_diversity}\")\n",
    "    avg_word_length = np.mean([len(w) for w in words]) if words else 0\n",
    "    # print(f\"Average word length: {avg_word_length}\")\n",
    "    avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
    "    # print(f\"Average sentence length: {avg_sentence_length}\")\n",
    "\n",
    "    return [\n",
    "        num_sentences,\n",
    "        num_words,\n",
    "        num_chars,\n",
    "        avg_word_length,\n",
    "        avg_sentence_length,\n",
    "        num_exclamations,\n",
    "        num_questions,\n",
    "        num_uppercase_words,\n",
    "        lexical_diversity\n",
    "    ]\n",
    "\n",
    "# Apply to both train and test\n",
    "train_stylo = train_data[\"posts\"].apply(extract_stylometric_features).tolist()\n",
    "test_stylo = test_data[\"posts\"].apply(extract_stylometric_features).tolist()\n",
    "# Convert to numpy arrays\n",
    "train_stylo_np = np.array(train_stylo)\n",
    "test_stylo_np = np.array(test_stylo)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_stylo_scaled = scaler.fit_transform(train_stylo_np)  \n",
    "test_stylo_scaled = scaler.transform(test_stylo_np)       \n",
    "\n",
    "# train_stylo_scaled = train_stylo_np\n",
    "# test_stylo_scaled = test_stylo_np      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f21d366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f21d366",
    "outputId": "71b744b5-15ad-4918-c596-eda5fc14e548"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meitongliu/miniconda/anaconda3/envs/psy/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define MBTI traits\n",
    "traits = ['I', 'E', 'N', 'S', 'T', 'F', 'J', 'P']\n",
    "\n",
    "# 1: Group posts by trait to build trait_keywords\n",
    "trait_groups = {trait: [] for trait in traits}\n",
    "for i, row in mbti_df.iterrows():\n",
    "    for t in row['type']:\n",
    "        if t in traits:\n",
    "            trait_groups[t].append(row['posts'])\n",
    "\n",
    "\n",
    "# 2: Extract top TF-IDF keywords for each trait\n",
    "def clean_tokenizer(text):\n",
    "    custom_stopwords = set([\n",
    "        'like', 'just', 'don', 'com', 'http', 'www', 'youtube', 'watch', 'infp',\n",
    "        'intj', 'infj', 'intp', 'enfp', 'entp', 'type', 'https', 've', 'istp'\n",
    "    ])\n",
    "    tokens = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n",
    "    return [t for t in tokens if t not in custom_stopwords]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "trait_keywords = {}\n",
    "top_k = 20\n",
    "\n",
    "for trait, posts in trait_groups.items():\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=clean_tokenizer,\n",
    "        stop_words='english',\n",
    "        max_features=1000\n",
    "    )\n",
    "    tfidf = vectorizer.fit_transform(posts)\n",
    "    mean_scores = tfidf.mean(axis=0).A1\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "    top_indices = mean_scores.argsort()[::-1][:top_k]\n",
    "    top_words = [vocab[i] for i in top_indices]\n",
    "    trait_keywords[trait] = top_words\n",
    "\n",
    "# 3: Build transition matrix\n",
    "co_matrix = np.zeros((8, 8))\n",
    "trait_index = {t: i for i, t in enumerate(traits)}\n",
    "for mbti in mbti_df['type']:\n",
    "    chars = list(mbti)\n",
    "    for t1 in chars:\n",
    "        for t2 in chars:\n",
    "            if t1 != t2:\n",
    "                i, j = trait_index[t1], trait_index[t2]\n",
    "                co_matrix[i][j] += 1\n",
    "row_sums = co_matrix.sum(axis=1, keepdims=True)\n",
    "transition_matrix = co_matrix / row_sums\n",
    "\n",
    "# 4: Define vector extraction function\n",
    "def extract_trait_vector(text, trait_keywords, use_transition=False, transition_matrix=None, normalize=True):\n",
    "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n",
    "    word_counts = Counter(words)\n",
    "    base_vector = np.array([\n",
    "        sum(word_counts.get(w, 0) for w in trait_keywords[t]) for t in traits\n",
    "    ])\n",
    "    # Print base_vector for debugging\n",
    "    # Print base_vector.shape # Sum the word counts of the top keywords for each trait, resulting in a vector of shape (8) for each post\n",
    "    if not use_transition:\n",
    "        return base_vector\n",
    "    if base_vector.sum() == 0:\n",
    "        return np.zeros(8)\n",
    "    if normalize:\n",
    "        base_vector = base_vector / base_vector.sum()\n",
    "    return np.dot(base_vector, transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27eec017",
   "metadata": {
    "id": "27eec017"
   },
   "outputs": [],
   "source": [
    "# vector (using transition matrix)\n",
    "train_trait_vector = np.vstack(\n",
    "    train_data['posts'].apply(lambda x: extract_trait_vector(x, trait_keywords, use_transition=True, transition_matrix=transition_matrix, normalize=True))\n",
    ")\n",
    "# print(train_trait_vector.shape) #construct the shape of （6940，8）\n",
    "\n",
    "test_trait_vector = np.vstack(\n",
    "    test_data['posts'].apply(lambda x: extract_trait_vector(x, trait_keywords, use_transition=True, transition_matrix=transition_matrix, normalize=True))\n",
    ")\n",
    "\n",
    "scaler_trait = StandardScaler()\n",
    "train_trait_vector_scaled = scaler_trait.fit_transform(train_trait_vector)  \n",
    "test_trait_vector_scaled = scaler_trait.transform(test_trait_vector)       \n",
    "\n",
    "\n",
    "# train_trait_vector_scaled = train_trait_vector\n",
    "# test_trait_vector_scaled = test_trait_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b96e85-5eb3-42d9-87d9-e0ade13d4c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1735, 8)\n"
     ]
    }
   ],
   "source": [
    "print(test_trait_vector_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a91c658",
   "metadata": {
    "id": "4a91c658"
   },
   "outputs": [],
   "source": [
    "# interface of the classification model\n",
    "\n",
    "# tf-idf : train_post  test_post\n",
    "\n",
    "# trait : train_trait_vector_scaled  test_trait_vector_scaled\n",
    "\n",
    "# stylo : train_stylo_np  test_stylo_np\n",
    "\n",
    "# trait+stylo. 17\n",
    "train_trait_stylo = np.hstack([train_stylo_np, train_trait_vector_scaled])\n",
    "test_trait_stylo = np.hstack([test_stylo_np, test_trait_vector_scaled])\n",
    "\n",
    "# tfidf+trait.  5008\n",
    "train_combined = np.hstack([train_post, train_trait_vector_scaled])\n",
    "test_combined = np.hstack([test_post, test_trait_vector_scaled])\n",
    "\n",
    "# tfidf+ stylo.  5009\n",
    "X_train_combined_stylo = np.hstack([train_post, train_stylo_np])\n",
    "X_test_combined_stylo = np.hstack([test_post, test_stylo_np])\n",
    "\n",
    "# all 5017\n",
    "train_combined_stylo = np.hstack([X_train_combined_stylo, train_trait_vector])\n",
    "test_combined_stylo = np.hstack([X_test_combined_stylo, test_trait_vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30abc922-8472-470a-8dcb-3795a5105906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE application\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=22)\n",
    "\n",
    "switch_of_SMOTE = 0   # 0: don't use smote        1: use smote\n",
    "if switch_of_SMOTE:\n",
    "    # 1. tfidf only\n",
    "    X_train_tfidf, y_train_tfidf = smote.fit_resample(train_post, train_target)\n",
    "    \n",
    "    # 2. trait only\n",
    "    X_train_trait , y_train_trait  = smote.fit_resample(train_trait_vector_scaled, train_target)\n",
    "    \n",
    "    # 3. stylo only\n",
    "    X_train_stylo , y_train_stylo  = smote.fit_resample(train_stylo_np, train_target)\n",
    "    \n",
    "    # 4. trait + stylo\n",
    "    X_train_trait_stylo , y_train_trait_stylo  = smote.fit_resample(train_trait_stylo, train_target)\n",
    "    \n",
    "    # 5. tfidf + trait\n",
    "    X_train_combined , y_train_combined  = smote.fit_resample(train_combined, train_target)\n",
    "    \n",
    "    # 6. tfidf + stylo\n",
    "    X_train_combined_stylo , y_train_combined_stylo  = smote.fit_resample(X_train_combined_stylo, train_target)\n",
    "    \n",
    "    # 7. tfidf + stylo + trait\n",
    "    X_train_all , y_train_all  = smote.fit_resample(train_combined_stylo, train_target)\n",
    "\n",
    "else:\n",
    "    # 1. tfidf only\n",
    "    X_train_tfidf, y_train_tfidf = train_post, train_target\n",
    "    \n",
    "    # 2. trait only\n",
    "    X_train_trait , y_train_trait  = train_trait_vector_scaled, train_target\n",
    "    \n",
    "    # 3. stylo only\n",
    "    X_train_stylo , y_train_stylo  = train_stylo_np, train_target\n",
    "    \n",
    "    # 4. trait + stylo\n",
    "    X_train_trait_stylo , y_train_trait_stylo  = train_trait_stylo, train_target\n",
    "    \n",
    "    # 5. tfidf + trait\n",
    "    X_train_combined , y_train_combined  = train_combined, train_target\n",
    "    \n",
    "    # 6. tfidf + stylo\n",
    "    X_train_combined_stylo , y_train_combined_stylo  = X_train_combined_stylo, train_target\n",
    "    \n",
    "    # 7. tfidf + stylo + trait\n",
    "    X_train_all , y_train_all  = train_combined_stylo, train_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbfef4f3-a597-44f9-bc93-5cc73e5cbb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def dir_run_logistic_regression(X_train, y_train, X_test, y_test, label_encoder=None, balance= 0, model_name=\"Logistic Regression\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a logistic regression model on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        X_train: ndarray, training features (SMOTE applied).\n",
    "        y_train: ndarray, training labels.\n",
    "        X_test: ndarray, test features.\n",
    "        y_test: ndarray, test labels.\n",
    "        label_encoder: sklearn LabelEncoder, used to convert label ids to names.\n",
    "        model_name: str, used to name the evaluation report.\n",
    "\n",
    "    Returns:\n",
    "        model: trained LogisticRegression model.\n",
    "    \"\"\"\n",
    "    print(f\"=== Training {model_name} ===\")\n",
    "    model = None\n",
    "    if balance:\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "    else:\n",
    "        model = LogisticRegression( max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n[Test Accuracy for {model_name}]: {acc:.4f}\")\n",
    "\n",
    "    print(\"Test accuracy score is \", accuracy_score(test_target, pred_combined))\n",
    "\n",
    "    print(f\"\\n[Classification Report for {model_name}]:\")\n",
    "    print(classification_report(y_test, preds, target_names=target_encoder.classes_, zero_division=0))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccca500a-4319-4402-ab91-af720fde5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training TFIDF  ===\n",
      "\n",
      "[Test Accuracy for TFIDF ]: 0.6882\n",
      "\n",
      "[Classification Report for TFIDF ]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.62        38\n",
      "           1       0.68      0.65      0.67       135\n",
      "           2       0.55      0.67      0.61        46\n",
      "           3       0.60      0.59      0.60       137\n",
      "           4       0.33      0.33      0.33         9\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.71      0.62      0.67         8\n",
      "           7       0.48      0.67      0.56        18\n",
      "           8       0.77      0.68      0.72       294\n",
      "           9       0.75      0.76      0.75       366\n",
      "          10       0.66      0.65      0.66       218\n",
      "          11       0.72      0.80      0.76       261\n",
      "          12       0.65      0.61      0.62        33\n",
      "          13       0.63      0.57      0.60        54\n",
      "          14       0.59      0.56      0.57        41\n",
      "          15       0.64      0.72      0.68        67\n",
      "\n",
      "    accuracy                           0.69      1735\n",
      "   macro avg       0.59      0.60      0.59      1735\n",
      "weighted avg       0.69      0.69      0.69      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_all = run_logistic_regression(\n",
    "    X_train_tfidf, y_train_tfidf,\n",
    "    test_post, test_target,\n",
    "    model_name=\"TFIDF \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835f654c-14c7-4dea-a5f6-389bc3d204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "\n",
    "def run_logistic_regression(X_train, y_train, X_test, y_test,\n",
    "                            label_encoder=None,\n",
    "                            model_name=\"Logistic Regression\",\n",
    "                            log_file_path=\"LR_non_smote_results_log.txt\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a logistic regression model, print and log results.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: training data.\n",
    "        X_test, y_test: testing data.\n",
    "        label_encoder: optional, for label names in classification report.\n",
    "        model_name: name for this model variant.\n",
    "        log_file_path: file to which logs are written.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    if label_encoder is not None:\n",
    "        target_names = label_encoder.classes_\n",
    "    else:\n",
    "        target_names = None\n",
    "\n",
    "    report = classification_report(y_test, preds, target_names=target_encoder.classes_, zero_division=0)\n",
    "\n",
    "    # Prepare log text\n",
    "    log_text = f\"\\n{'='*60}\\nModel: {model_name}\\nAccuracy: {acc:.4f}\\n{report}\\n\"\n",
    "\n",
    "    # Print to console\n",
    "    print(log_text)\n",
    "\n",
    "    # Append to log file\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        f.write(log_text)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0b3d7a2-77d4-4d3e-bb28-552b7ee30722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: TF-IDF only\n",
      "Accuracy: 0.6680\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.45      0.68      0.54        38\n",
      "        ENFP       0.66      0.63      0.64       135\n",
      "        ENTJ       0.45      0.67      0.54        46\n",
      "        ENTP       0.62      0.62      0.62       137\n",
      "        ESFJ       0.33      0.33      0.33         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.62      0.62      0.62         8\n",
      "        ESTP       0.44      0.67      0.53        18\n",
      "        INFJ       0.79      0.64      0.71       294\n",
      "        INFP       0.76      0.70      0.73       366\n",
      "        INTJ       0.68      0.63      0.65       218\n",
      "        INTP       0.74      0.77      0.75       261\n",
      "        ISFJ       0.59      0.67      0.63        33\n",
      "        ISFP       0.47      0.57      0.52        54\n",
      "        ISTJ       0.50      0.56      0.53        41\n",
      "        ISTP       0.57      0.76      0.65        67\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.54      0.60      0.56      1735\n",
      "weighted avg       0.68      0.67      0.67      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: Trait only\n",
      "Accuracy: 0.1026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.02      0.03      0.02        38\n",
      "        ENFP       0.07      0.04      0.05       135\n",
      "        ENTJ       0.03      0.04      0.04        46\n",
      "        ENTP       0.07      0.07      0.07       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.01      0.25      0.02         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.19      0.05      0.08       294\n",
      "        INFP       0.15      0.02      0.03       366\n",
      "        INTJ       0.18      0.22      0.20       218\n",
      "        INTP       0.24      0.17      0.20       261\n",
      "        ISFJ       0.16      0.33      0.22        33\n",
      "        ISFP       0.08      0.15      0.10        54\n",
      "        ISTJ       0.09      0.22      0.13        41\n",
      "        ISTP       0.07      0.24      0.11        67\n",
      "\n",
      "    accuracy                           0.10      1735\n",
      "   macro avg       0.09      0.11      0.08      1735\n",
      "weighted avg       0.15      0.10      0.10      1735\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meitongliu/miniconda/anaconda3/envs/psy/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: Stylo only\n",
      "Accuracy: 0.0790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.03      0.05      0.04        38\n",
      "        ENFP       0.00      0.00      0.00       135\n",
      "        ENTJ       0.02      0.09      0.03        46\n",
      "        ENTP       0.12      0.01      0.03       137\n",
      "        ESFJ       0.00      0.11      0.01         9\n",
      "        ESFP       0.01      0.40      0.02        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.02      0.22      0.03        18\n",
      "        INFJ       0.20      0.17      0.18       294\n",
      "        INFP       0.00      0.00      0.00       366\n",
      "        INTJ       0.20      0.28      0.23       218\n",
      "        INTP       0.25      0.03      0.05       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.08      1735\n",
      "   macro avg       0.05      0.09      0.04      1735\n",
      "weighted avg       0.11      0.08      0.07      1735\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meitongliu/miniconda/anaconda3/envs/psy/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: Trait + Stylo\n",
      "Accuracy: 0.0928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.02      0.03      0.02        38\n",
      "        ENFP       0.20      0.05      0.08       135\n",
      "        ENTJ       0.03      0.15      0.06        46\n",
      "        ENTP       0.04      0.01      0.01       137\n",
      "        ESFJ       0.01      0.11      0.02         9\n",
      "        ESFP       0.01      0.20      0.02        10\n",
      "        ESTJ       0.01      0.25      0.03         8\n",
      "        ESTP       0.02      0.11      0.03        18\n",
      "        INFJ       0.23      0.11      0.15       294\n",
      "        INFP       0.25      0.01      0.02       366\n",
      "        INTJ       0.22      0.24      0.23       218\n",
      "        INTP       0.22      0.09      0.13       261\n",
      "        ISFJ       0.08      0.24      0.12        33\n",
      "        ISFP       0.11      0.09      0.10        54\n",
      "        ISTJ       0.07      0.12      0.09        41\n",
      "        ISTP       0.06      0.15      0.08        67\n",
      "\n",
      "    accuracy                           0.09      1735\n",
      "   macro avg       0.10      0.12      0.07      1735\n",
      "weighted avg       0.18      0.09      0.10      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: TF-IDF + Trait\n",
      "Accuracy: 0.6576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.41      0.68      0.51        38\n",
      "        ENFP       0.66      0.62      0.64       135\n",
      "        ENTJ       0.41      0.57      0.48        46\n",
      "        ENTP       0.58      0.59      0.58       137\n",
      "        ESFJ       0.38      0.33      0.35         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.56      0.62      0.59         8\n",
      "        ESTP       0.41      0.67      0.51        18\n",
      "        INFJ       0.79      0.63      0.70       294\n",
      "        INFP       0.77      0.71      0.74       366\n",
      "        INTJ       0.67      0.61      0.64       218\n",
      "        INTP       0.76      0.76      0.76       261\n",
      "        ISFJ       0.51      0.70      0.59        33\n",
      "        ISFP       0.41      0.57      0.48        54\n",
      "        ISTJ       0.52      0.56      0.54        41\n",
      "        ISTP       0.57      0.75      0.65        67\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.53      0.59      0.55      1735\n",
      "weighted avg       0.68      0.66      0.66      1735\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meitongliu/miniconda/anaconda3/envs/psy/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: TF-IDF + Stylo\n",
      "Accuracy: 0.3948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.35      0.58      0.44        38\n",
      "        ENFP       0.39      0.44      0.41       135\n",
      "        ENTJ       0.12      0.50      0.20        46\n",
      "        ENTP       0.43      0.43      0.43       137\n",
      "        ESFJ       0.12      0.33      0.18         9\n",
      "        ESFP       0.05      0.10      0.07        10\n",
      "        ESTJ       0.35      0.75      0.48         8\n",
      "        ESTP       0.24      0.72      0.36        18\n",
      "        INFJ       0.34      0.26      0.29       294\n",
      "        INFP       0.60      0.40      0.48       366\n",
      "        INTJ       0.49      0.32      0.39       218\n",
      "        INTP       0.62      0.44      0.52       261\n",
      "        ISFJ       0.51      0.58      0.54        33\n",
      "        ISFP       0.25      0.26      0.25        54\n",
      "        ISTJ       0.14      0.41      0.21        41\n",
      "        ISTP       0.55      0.63      0.58        67\n",
      "\n",
      "    accuracy                           0.39      1735\n",
      "   macro avg       0.35      0.45      0.36      1735\n",
      "weighted avg       0.46      0.39      0.41      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: TF-IDF + Stylo + Trait\n",
      "Accuracy: 0.2565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.12      0.47      0.20        38\n",
      "        ENFP       0.60      0.18      0.27       135\n",
      "        ENTJ       0.11      0.30      0.16        46\n",
      "        ENTP       0.58      0.20      0.30       137\n",
      "        ESFJ       0.10      0.33      0.15         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.27      0.50      0.35         8\n",
      "        ESTP       0.06      0.61      0.11        18\n",
      "        INFJ       0.26      0.25      0.25       294\n",
      "        INFP       0.48      0.17      0.26       366\n",
      "        INTJ       0.27      0.40      0.32       218\n",
      "        INTP       0.58      0.25      0.35       261\n",
      "        ISFJ       0.33      0.18      0.24        33\n",
      "        ISFP       0.10      0.30      0.15        54\n",
      "        ISTJ       0.43      0.32      0.37        41\n",
      "        ISTP       0.39      0.28      0.33        67\n",
      "\n",
      "    accuracy                           0.26      1735\n",
      "   macro avg       0.29      0.30      0.24      1735\n",
      "weighted avg       0.40      0.26      0.28      1735\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meitongliu/miniconda/anaconda3/envs/psy/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model1 = run_logistic_regression(X_train_tfidf, y_train_tfidf, test_post, test_target,  label_encoder=None, model_name=\"TF-IDF only\")\n",
    "model2 = run_logistic_regression(X_train_trait, y_train_trait, test_trait_vector_scaled, test_target,  label_encoder=None, model_name=\"Trait only\")\n",
    "model3 = run_logistic_regression(X_train_stylo, y_train_stylo, test_stylo_np, test_target,  label_encoder=None, model_name=\"Stylo only\")\n",
    "model4 = run_logistic_regression(X_train_trait_stylo, y_train_trait_stylo, test_trait_stylo, test_target,  label_encoder=None, model_name=\"Trait + Stylo\")\n",
    "model5 = run_logistic_regression(X_train_combined, y_train_combined, test_combined, test_target,  label_encoder=None, model_name=\"TF-IDF + Trait\")\n",
    "model6 = run_logistic_regression(X_train_combined_stylo, y_train_combined_stylo, X_test_combined_stylo, test_target,  label_encoder=None, model_name=\"TF-IDF + Stylo\")\n",
    "model7 = run_logistic_regression(X_train_all, y_train_all, test_combined_stylo, test_target,  label_encoder=None, model_name=\"TF-IDF + Stylo + Trait\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f1aefc-67f1-4dec-b83f-81513c30fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def run_svm_classifier(X_train, y_train, X_test, y_test,\n",
    "                       label_encoder=None,\n",
    "                       model_name=\"SVM\",\n",
    "                       log_file_path=\"SVM_non_smote_results_log.txt\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a Support Vector Machine classifier, print and log results.\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train: training data.\n",
    "        X_test, y_test: test data.\n",
    "        label_encoder: optional LabelEncoder to show label names in report.\n",
    "        model_name: name to label this model variant.\n",
    "        log_file_path: path to append logs to.\n",
    "\n",
    "    Returns:\n",
    "        model: trained sklearn.svm.SVC model.\n",
    "    \"\"\"\n",
    "    model = SVC(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "\n",
    "    report = classification_report(y_test, preds, target_names=target_encoder.classes_, zero_division=0)\n",
    "\n",
    "    # Log + print output\n",
    "    log_text = f\"\\n{'='*60}\\nModel: {model_name}\\nAccuracy: {acc:.4f}\\n{report}\\n\"\n",
    "    print(log_text)\n",
    "\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        f.write(log_text)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d6ea1ff-71f1-47c7-a807-6fe64a1218c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: SVM with TF-IDF\n",
      "Accuracy: 0.6490\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.65      0.29      0.40        38\n",
      "        ENFP       0.75      0.57      0.65       135\n",
      "        ENTJ       0.67      0.26      0.38        46\n",
      "        ENTP       0.66      0.51      0.58       137\n",
      "        ESFJ       0.50      0.22      0.31         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.71      0.28      0.40        18\n",
      "        INFJ       0.67      0.69      0.68       294\n",
      "        INFP       0.59      0.85      0.70       366\n",
      "        INTJ       0.67      0.64      0.65       218\n",
      "        INTP       0.65      0.83      0.73       261\n",
      "        ISFJ       0.82      0.27      0.41        33\n",
      "        ISFP       0.80      0.37      0.51        54\n",
      "        ISTJ       0.76      0.32      0.45        41\n",
      "        ISTP       0.75      0.54      0.63        67\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.60      0.42      0.47      1735\n",
      "weighted avg       0.66      0.65      0.63      1735\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm = run_svm_classifier(\n",
    "    X_train_tfidf, y_train_tfidf,\n",
    "    test_post, test_target,\n",
    "    label_encoder=target_encoder,\n",
    "    model_name=\"SVM with TF-IDF\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "788f23c0-9ff8-4911-9369-8684ea9a6f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: TF-IDF only\n",
      "Accuracy: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.67      0.26      0.38        38\n",
      "        ENFP       0.76      0.59      0.66       135\n",
      "        ENTJ       0.76      0.28      0.41        46\n",
      "        ENTP       0.68      0.52      0.59       137\n",
      "        ESFJ       0.33      0.11      0.17         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.83      0.28      0.42        18\n",
      "        INFJ       0.67      0.69      0.68       294\n",
      "        INFP       0.60      0.86      0.70       366\n",
      "        INTJ       0.65      0.64      0.65       218\n",
      "        INTP       0.65      0.84      0.74       261\n",
      "        ISFJ       0.83      0.30      0.44        33\n",
      "        ISFP       0.78      0.33      0.47        54\n",
      "        ISTJ       0.75      0.29      0.42        41\n",
      "        ISTP       0.76      0.57      0.65        67\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.61      0.41      0.46      1735\n",
      "weighted avg       0.66      0.65      0.64      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: Trait only\n",
      "Accuracy: 0.2098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.00      0.00      0.00       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.00      0.00      0.00       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.15      0.02      0.04       294\n",
      "        INFP       0.21      0.95      0.35       366\n",
      "        INTJ       0.20      0.03      0.05       218\n",
      "        INTP       0.50      0.00      0.01       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.09      0.02      0.03        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.21      1735\n",
      "   macro avg       0.07      0.06      0.03      1735\n",
      "weighted avg       0.17      0.21      0.09      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: Stylo only\n",
      "Accuracy: 0.2110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.00      0.00      0.00       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.00      0.00      0.00       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.00      0.00      0.00       294\n",
      "        INFP       0.21      1.00      0.35       366\n",
      "        INTJ       0.00      0.00      0.00       218\n",
      "        INTP       0.00      0.00      0.00       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.21      1735\n",
      "   macro avg       0.01      0.06      0.02      1735\n",
      "weighted avg       0.04      0.21      0.07      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: Trait + Stylo\n",
      "Accuracy: 0.2110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.00      0.00      0.00       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.00      0.00      0.00       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.00      0.00      0.00       294\n",
      "        INFP       0.21      1.00      0.35       366\n",
      "        INTJ       0.00      0.00      0.00       218\n",
      "        INTP       0.00      0.00      0.00       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.21      1735\n",
      "   macro avg       0.01      0.06      0.02      1735\n",
      "weighted avg       0.04      0.21      0.07      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: TF-IDF + Trait\n",
      "Accuracy: 0.5372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.73      0.33      0.45       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.67      0.31      0.43       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.59      0.62      0.61       294\n",
      "        INFP       0.45      0.87      0.60       366\n",
      "        INTJ       0.62      0.55      0.58       218\n",
      "        INTP       0.56      0.75      0.65       261\n",
      "        ISFJ       0.60      0.09      0.16        33\n",
      "        ISFP       0.35      0.15      0.21        54\n",
      "        ISTJ       0.43      0.15      0.22        41\n",
      "        ISTP       0.60      0.13      0.22        67\n",
      "\n",
      "    accuracy                           0.54      1735\n",
      "   macro avg       0.35      0.25      0.26      1735\n",
      "weighted avg       0.53      0.54      0.49      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: TF-IDF + Stylo\n",
      "Accuracy: 0.2110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.00      0.00      0.00       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.00      0.00      0.00       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.00      0.00      0.00       294\n",
      "        INFP       0.21      1.00      0.35       366\n",
      "        INTJ       0.00      0.00      0.00       218\n",
      "        INTP       0.00      0.00      0.00       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.21      1735\n",
      "   macro avg       0.01      0.06      0.02      1735\n",
      "weighted avg       0.04      0.21      0.07      1735\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: TF-IDF + Stylo + Trait\n",
      "Accuracy: 0.2110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.00      0.00      0.00       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.00      0.00      0.00       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.00      0.00      0.00       294\n",
      "        INFP       0.21      1.00      0.35       366\n",
      "        INTJ       0.00      0.00      0.00       218\n",
      "        INTP       0.00      0.00      0.00       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.21      1735\n",
      "   macro avg       0.01      0.06      0.02      1735\n",
      "weighted avg       0.04      0.21      0.07      1735\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = run_svm_classifier(X_train_tfidf, y_train_tfidf, test_post, test_target,  label_encoder=None, model_name=\"TF-IDF only\")\n",
    "model2 = run_svm_classifier(X_train_trait, y_train_trait, test_trait_vector_scaled, test_target,  label_encoder=None, model_name=\"Trait only\")\n",
    "model3 = run_svm_classifier(X_train_stylo, y_train_stylo, test_stylo_np, test_target,  label_encoder=None, model_name=\"Stylo only\")\n",
    "model4 = run_svm_classifier(X_train_trait_stylo, y_train_trait_stylo, test_trait_stylo, test_target,  label_encoder=None, model_name=\"Trait + Stylo\")\n",
    "model5 = run_svm_classifier(X_train_combined, y_train_combined, test_combined, test_target,  label_encoder=None, model_name=\"TF-IDF + Trait\")\n",
    "model6 = run_svm_classifier(X_train_combined_stylo, y_train_combined_stylo, X_test_combined_stylo, test_target,  label_encoder=None, model_name=\"TF-IDF + Stylo\")\n",
    "model7 = run_svm_classifier(X_train_all, y_train_all, test_combined_stylo, test_target,  label_encoder=None, model_name=\"TF-IDF + Stylo + Trait\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
