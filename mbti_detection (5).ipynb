{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1db60baf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1db60baf",
        "outputId": "9c1aafab-ba38-4860-a13e-8492682a06fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')#connect with the google drive to get the data\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "mbti_df = pd.read_csv('/content/drive/MyDrive/Comp8535_Group_Project-gennie-dev/mbti_1.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "00d43947",
      "metadata": {
        "id": "00d43947"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Text normalization\n",
        "# (i) convert to lowercase;\n",
        "# (ii) remove url;\n",
        "# (iii) remove numbers;\n",
        "# (iv) remove non-alphanumeric characters (punctuation, special characters);\n",
        "# (v) remove underscores and signs;\n",
        "# (vi) replace multiple spaces with single spaces;\n",
        "# (vii) remove stopwords;\n",
        "# (viii) remove one-letter words;\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    pattern = re.compile(r'https?://[a-zA-Z0-9./-]*/[a-zA-Z0-9?=_.]*[_0-9.a-zA-Z/-]*')\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    pattern = re.compile(r'[0-9]')\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    pattern = re.compile(r'\\W+')\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    pattern = re.compile(r'[_+]')\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "    pattern = re.compile(r'\\s+')\n",
        "    text = re.sub(pattern, ' ', text).strip()\n",
        "    stop_words = stopwords.words(\"english\")\n",
        "    text = \" \".join([w for w in text.split() if w not in stop_words])\n",
        "    text = ' '.join([word for word in text.split() if len(word) > 1])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e9ab404",
      "metadata": {
        "id": "1e9ab404"
      },
      "outputs": [],
      "source": [
        "# 2. Lemmatization\n",
        "# (i) use NLTK's lemmatizer\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5656c103",
      "metadata": {
        "id": "5656c103"
      },
      "outputs": [],
      "source": [
        "# 3. Select classification dimension (16-class classification or binary classification on single dimension)\n",
        "def select_classification_dimension(df, num=0):\n",
        "    if num == 16:\n",
        "        return df['type']\n",
        "    elif 1 <= num <= 4:\n",
        "        return df['type'].str[num-1]\n",
        "    else:\n",
        "        print(\"selection error of classification dimension!\")\n",
        "        return df['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "086bb08d",
      "metadata": {
        "id": "086bb08d"
      },
      "outputs": [],
      "source": [
        "# 4. Label encoding\n",
        "# (i) creates an array corresponding to the type labels.\n",
        "def encode_labels(column):\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(column)\n",
        "    mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
        "    print(f\"Label encoding mapping: {mapping}\")\n",
        "    print(f\"Encoded label examples: {y[:5]}\")\n",
        "    print(f\"Unique encoded labels: {np.unique(y)}\")\n",
        "    return y, le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6014ee67",
      "metadata": {
        "id": "6014ee67"
      },
      "outputs": [],
      "source": [
        "mbti_df[\"posts\"] = mbti_df[\"posts\"].str.lower()       #converts text in posts to lowercase as it is preferred in nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9877527c",
      "metadata": {
        "id": "9877527c"
      },
      "outputs": [],
      "source": [
        "for i in range(len(mbti_df)):\n",
        "  post_temp=mbti_df._get_value(i, 'posts')\n",
        "  pattern = re.compile(r'https?://[a-zA-Z0-9./-]*/[a-zA-Z0-9?=_.]*[_0-9.a-zA-Z/-]*')    #to match url links present in the post\n",
        "  post_temp= re.sub(pattern, ' ', post_temp)                                            #to replace that url link with space\n",
        "  mbti_df._set_value(i, 'posts',post_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f236c905",
      "metadata": {
        "id": "f236c905"
      },
      "outputs": [],
      "source": [
        "for i in range(len(mbti_df)):\n",
        "  post_temp=mbti_df._get_value(i, 'posts')\n",
        "  pattern = re.compile(r'[0-9]')                                    #to match numbers from 0 to 9\n",
        "  post_temp= re.sub(pattern, ' ', post_temp)                        #to replace them with space\n",
        "  pattern = re.compile('\\W+')                                       #to match alphanumeric characters\n",
        "  post_temp= re.sub(pattern, ' ', post_temp)                        #to replace them with space\n",
        "  pattern = re.compile(r'[_+]')\n",
        "  post_temp= re.sub(pattern, ' ', post_temp)\n",
        "  mbti_df._set_value(i, 'posts',post_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "19e723f6",
      "metadata": {
        "id": "19e723f6"
      },
      "outputs": [],
      "source": [
        "for i in range(len(mbti_df)):\n",
        "  post_temp=mbti_df._get_value(i, 'posts')\n",
        "  pattern = re.compile('\\s+')                                     #to match multiple whitespaces\n",
        "  post_temp= re.sub(pattern, ' ', post_temp)                      #to replace them with single whitespace\n",
        "  mbti_df._set_value(i, 'posts', post_temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9390486b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9390486b",
        "outputId": "f31599f0-42ac-4329-c760-98b139d7a615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "acf46323",
      "metadata": {
        "id": "acf46323"
      },
      "outputs": [],
      "source": [
        "remove_words = stopwords.words(\"english\")\n",
        "for i in range(mbti_df.shape[0]):\n",
        "  post_temp=mbti_df._get_value(i, 'posts')\n",
        "  post_temp=\" \".join([w for w in post_temp.split(' ') if w not in remove_words])    #to remove stopwords\n",
        "  mbti_df._set_value(i, 'posts', post_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c006c461",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c006c461",
        "outputId": "4f4064d7-b3b9-4315-8aba-bbda63a5f9ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "16c064be",
      "metadata": {
        "id": "16c064be"
      },
      "outputs": [],
      "source": [
        "for i in range(mbti_df.shape[0]):\n",
        "  post_temp=mbti_df._get_value(i, 'posts')\n",
        "  post_temp=\" \".join([lemmatizer.lemmatize(w) for w in post_temp.split(' ')])   #to implement lemmetization i.e. to group together different forms of a word\n",
        "  mbti_df._set_value(i, 'posts', post_temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "700b3c34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700b3c34",
        "outputId": "0e9c2a2f-0dad-49b0-f73e-f18203c980f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      type                                              posts\n",
            "0     INFJ   enfp intj moment sportscenter top ten play pr...\n",
            "1     ENTP   finding lack post alarming sex boring positio...\n",
            "2     INTP   good one course say know blessing curse absol...\n",
            "3     INTJ   dear intp enjoyed conversation day esoteric g...\n",
            "4     ENTJ   fired another silly misconception approaching...\n",
            "...    ...                                                ...\n",
            "8670  ISFP   ixfp always think cat fi doms reason especial...\n",
            "8671  ENFP   thread already exists someplace else post hec...\n",
            "8672  INTP   many question thing would take purple pill pi...\n",
            "8673  INFP   conflicted right come wanting child honestly ...\n",
            "8674  INFP   long since personalitycafe although seem chan...\n",
            "\n",
            "[8675 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(mbti_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c3f00092",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3f00092",
        "outputId": "a57f0672-9d64-444f-d3dd-8dd1ac8f11e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      type                                              posts\n",
            "7814  INFP   macona depends big family extroverted people ...\n",
            "2233  ENFJ   blodsmak sveltihel brilliant episode regenera...\n",
            "7261  INFJ   heylena lol compliment accepted thank jeesh f...\n",
            "7794  INFJ   pac right rocket coffin like packed warhead r...\n",
            "2950  INTJ   title thread misleading mention world dominat...\n",
            "...    ...                                                ...\n",
            "2006  INTJ   one sentence restrictive accurately portray d...\n",
            "7137  ISTJ   wanted like odd hybrid dr james wilson house ...\n",
            "6091  ENTP   took cognitive process test got cognitive pro...\n",
            "2997  INFJ   get caught fantacy relationship better forget...\n",
            "5458  ENTJ   doll love movie listed make think tritype one...\n",
            "\n",
            "[1735 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data=train_test_split(mbti_df,test_size=0.2,random_state=42,stratify=mbti_df.type)\n",
        "\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0789985d",
      "metadata": {
        "id": "0789985d"
      },
      "outputs": [],
      "source": [
        "vectorizer=TfidfVectorizer( max_features=5000,stop_words='english')\n",
        "vectorizer.fit(train_data.posts)\n",
        "train_post=vectorizer.transform(train_data.posts).toarray()\n",
        "test_post=vectorizer.transform(test_data.posts).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3338d73b",
      "metadata": {
        "id": "3338d73b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "target_encoder=LabelEncoder()\n",
        "train_target=target_encoder.fit_transform(train_data.type)\n",
        "test_target=target_encoder.fit_transform(test_data.type)\n",
        "\n",
        "# # Set classification mode\n",
        "# classification_mode = 3\n",
        "\n",
        "# # Get binary classification labels\n",
        "# train_labels = select_classification_dimension(train_data, classification_mode)\n",
        "# test_labels = select_classification_dimension(test_data, classification_mode)\n",
        "\n",
        "# # Encode labels\n",
        "# target_encoder = LabelEncoder()\n",
        "# train_target = target_encoder.fit_transform(train_labels)\n",
        "# test_target = target_encoder.fit_transform(test_labels)\n",
        "\n",
        "# # Verify labels\n",
        "# print(f\"Label classes: {target_encoder.classes_}\")\n",
        "# print(f\"Encoded train labels (first 5): {train_target[:5]}\")\n",
        "# print(f\"Unique encoded labels: {np.unique(train_target)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "84306028",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84306028",
        "outputId": "3cab2b60-33c4-4b01-a7cc-6b4cf0d6af01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def extract_stylometric_features(text):\n",
        "    # print(f\"Input text: {text}\")\n",
        "    sentences = sent_tokenize(text)\n",
        "    # print(f\"Split sentences: {sentences}\")\n",
        "    words = word_tokenize(text)\n",
        "    # print(f\"Words: {words}\")\n",
        "    num_sentences = len(sentences)\n",
        "    # print(f\"Number of sentences: {num_sentences}\")\n",
        "    num_words = len(words)\n",
        "    # print(f\"Number of words: {num_words}\")\n",
        "    num_chars = len(text)\n",
        "    # print(f\"Number of characters: {num_chars}\")\n",
        "    num_exclamations = text.count('!')\n",
        "    # print(f\"Number of exclamation marks: {num_exclamations}\")\n",
        "    num_questions = text.count('?')\n",
        "    # print(f\"Number of question marks: {num_questions}\")\n",
        "    num_uppercase_words = sum(1 for w in words if w.isupper())\n",
        "    # print(f\"Number of uppercase words: {num_uppercase_words}\")\n",
        "    lexical_diversity = len(set(words)) / num_words if num_words > 0 else 0\n",
        "    # print(f\"Lexical diversity: {lexical_diversity}\")\n",
        "    avg_word_length = np.mean([len(w) for w in words]) if words else 0\n",
        "    # print(f\"Average word length: {avg_word_length}\")\n",
        "    avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
        "    # print(f\"Average sentence length: {avg_sentence_length}\")\n",
        "\n",
        "    return [\n",
        "        num_sentences,\n",
        "        num_words,\n",
        "        num_chars,\n",
        "        avg_word_length,\n",
        "        avg_sentence_length,\n",
        "        num_exclamations,\n",
        "        num_questions,\n",
        "        num_uppercase_words,\n",
        "        lexical_diversity\n",
        "    ]\n",
        "\n",
        "# Apply to both train and test\n",
        "train_stylo = train_data[\"posts\"].apply(extract_stylometric_features).tolist()\n",
        "test_stylo = test_data[\"posts\"].apply(extract_stylometric_features).tolist()\n",
        "# print(\"First 3 elements of train_stylo:\", train_stylo[:3])\n",
        "# print(\"First 3 elements of test_stylo:\", test_stylo[:3])\n",
        "# Convert to numpy arrays\n",
        "train_stylo_np = np.array(train_stylo)\n",
        "test_stylo_np = np.array(test_stylo)\n",
        "# print(\"Shape of train_stylo_np:\", train_stylo_np.shape)\n",
        "# print(\"Shape of test_stylo_np:\", test_stylo_np.shape)\n",
        "# print(\"First 3 rows of train_stylo_np:\", train_stylo_np[:3, :])\n",
        "\n",
        "X_train_combined_stylo = np.hstack([train_post, train_stylo_np])\n",
        "X_test_combined_stylo = np.hstack([test_post, test_stylo_np])\n",
        "# print(\"Shape of train_post:\", train_post.shape)\n",
        "# print(\"Shape of test_post:\", test_post.shape)\n",
        "# print(\"Shape of X_train_combined:\", X_train_combined.shape)\n",
        "# print(\"Shape of X_test_combined:\", X_test_combined.shape)\n",
        "\n",
        "# sample_post = train_data[\"posts\"].iloc[0]\n",
        "# features = extract_stylometric_features(sample_post)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3f21d366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f21d366",
        "outputId": "71b744b5-15ad-4918-c596-eda5fc14e548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Define MBTI traits\n",
        "traits = ['I', 'E', 'N', 'S', 'T', 'F', 'J', 'P']\n",
        "\n",
        "# 1: Group posts by trait to build trait_keywords\n",
        "trait_groups = {trait: [] for trait in traits}\n",
        "for i, row in mbti_df.iterrows():\n",
        "    for t in row['type']:\n",
        "        if t in traits:\n",
        "            trait_groups[t].append(row['posts'])\n",
        "\n",
        "# print(\"trait_groups['I']:\")\n",
        "# for post in trait_groups['I']:\n",
        "#     print(f\"  - {post[:30]}...\")\n",
        "# print(\"\\ntrait_groups['E']:\")\n",
        "# for post in trait_groups['E']:\n",
        "#     print(f\"  - {post[:30]}...\")\n",
        "# print(\"\\ntrait_groups['N']:\")\n",
        "# for post in trait_groups['N']:\n",
        "#     print(f\"  - {post[:30]}...\")\n",
        "\n",
        "# 2: Extract top TF-IDF keywords for each trait\n",
        "def clean_tokenizer(text):\n",
        "    custom_stopwords = set([\n",
        "        'like', 'just', 'don', 'com', 'http', 'www', 'youtube', 'watch', 'infp',\n",
        "        'intj', 'infj', 'intp', 'enfp', 'entp', 'type', 'https', 've', 'istp'\n",
        "    ])\n",
        "    tokens = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n",
        "    return [t for t in tokens if t not in custom_stopwords]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "trait_keywords = {}\n",
        "top_k = 20\n",
        "\n",
        "for trait, posts in trait_groups.items():\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        tokenizer=clean_tokenizer,\n",
        "        stop_words='english',\n",
        "        max_features=1000\n",
        "    )\n",
        "    tfidf = vectorizer.fit_transform(posts)\n",
        "    mean_scores = tfidf.mean(axis=0).A1\n",
        "    vocab = vectorizer.get_feature_names_out()\n",
        "    top_indices = mean_scores.argsort()[::-1][:top_k]\n",
        "    top_words = [vocab[i] for i in top_indices]\n",
        "    trait_keywords[trait] = top_words\n",
        "\n",
        "# 3: Build transition matrix\n",
        "co_matrix = np.zeros((8, 8))\n",
        "trait_index = {t: i for i, t in enumerate(traits)}\n",
        "for mbti in mbti_df['type']:\n",
        "    chars = list(mbti)\n",
        "    for t1 in chars:\n",
        "        for t2 in chars:\n",
        "            if t1 != t2:\n",
        "                i, j = trait_index[t1], trait_index[t2]\n",
        "                co_matrix[i][j] += 1\n",
        "row_sums = co_matrix.sum(axis=1, keepdims=True)\n",
        "transition_matrix = co_matrix / row_sums\n",
        "\n",
        "# 4: Define vector extraction function\n",
        "def extract_trait_vector(text, trait_keywords, use_transition=False, transition_matrix=None, normalize=True):\n",
        "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n",
        "    word_counts = Counter(words)\n",
        "    base_vector = np.array([\n",
        "        sum(word_counts.get(w, 0) for w in trait_keywords[t]) for t in traits\n",
        "    ])\n",
        "    # Print base_vector for debugging\n",
        "    # Print base_vector.shape # Sum the word counts of the top keywords for each trait, resulting in a vector of shape (8) for each post\n",
        "    if not use_transition:\n",
        "        return base_vector\n",
        "    if base_vector.sum() == 0:\n",
        "        return np.zeros(8)\n",
        "    if normalize:\n",
        "        base_vector = base_vector / base_vector.sum()\n",
        "    return np.dot(base_vector, transition_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "27eec017",
      "metadata": {
        "id": "27eec017"
      },
      "outputs": [],
      "source": [
        "# vector (using transition matrix)\n",
        "train_trait_vector = np.vstack(\n",
        "    train_data['posts'].apply(lambda x: extract_trait_vector(x, trait_keywords, use_transition=True, transition_matrix=transition_matrix, normalize=True))\n",
        ")\n",
        "# print(train_trait_vector.shape) #construct the shape of （6940，8）\n",
        "\n",
        "test_trait_vector = np.vstack(\n",
        "    test_data['posts'].apply(lambda x: extract_trait_vector(x, trait_keywords, use_transition=True, transition_matrix=transition_matrix, normalize=True))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4a91c658",
      "metadata": {
        "id": "4a91c658"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_combined = np.hstack([train_post, train_trait_vector])\n",
        "# print(train_combined.shape)\n",
        "test_combined = np.hstack([test_post, test_trait_vector])\n",
        "train_combined_stylo = np.hstack([X_train_combined_stylo, train_trait_vector])\n",
        "test_combined_stylo = np.hstack([X_test_combined_stylo, test_trait_vector])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2xuFI02MFuO5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xuFI02MFuO5",
        "outputId": "b4b9d238-cbd7-4baa-e76c-ed52ee67380d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for XGBoost Classifier with TF-IDF Features Only:\n",
            " 0.6587896253602306\n",
            "Classification Report of XGBoost Classifier with TF-IDF Features Only:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.59      0.42      0.49        38\n",
            "        ENFP       0.69      0.59      0.64       135\n",
            "        ENTJ       0.67      0.39      0.49        46\n",
            "        ENTP       0.59      0.59      0.59       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       1.00      0.25      0.40         8\n",
            "        ESTP       0.46      0.33      0.39        18\n",
            "        INFJ       0.68      0.72      0.70       294\n",
            "        INFP       0.66      0.80      0.72       366\n",
            "        INTJ       0.63      0.67      0.65       218\n",
            "        INTP       0.70      0.77      0.73       261\n",
            "        ISFJ       0.64      0.55      0.59        33\n",
            "        ISFP       0.66      0.35      0.46        54\n",
            "        ISTJ       0.65      0.41      0.51        41\n",
            "        ISTP       0.61      0.52      0.56        67\n",
            "\n",
            "    accuracy                           0.66      1735\n",
            "   macro avg       0.64      0.47      0.51      1735\n",
            "weighted avg       0.66      0.66      0.65      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:38:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# Classifier 1: XGBoost Classifier\n",
        "# Use TF-IDF features only\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model_xgb_tfidf = xgb.XGBClassifier(tree_method='hist', device='cuda')\n",
        "model_xgb_tfidf.fit(train_post, train_target)\n",
        "pred_tfidf = model_xgb_tfidf.predict(test_post)\n",
        "print(\"Test accuracy score for XGBoost Classifier with TF-IDF Features Only:\\n\", accuracy_score(test_target, pred_tfidf))\n",
        "print(\"Classification Report of XGBoost Classifier with TF-IDF Features Only:\")\n",
        "print(classification_report(test_target, pred_tfidf, target_names=target_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "_Uxz0dElFub4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Uxz0dElFub4",
        "outputId": "d88c62b0-e737-41c8-cfe4-28f800727bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for XGBoost Classifier with TF-IDF Features+Trait Vector:\n",
            " 0.6651296829971182\n",
            "Classification Report of XGBoost Classifier with TF-IDF Features+Trait Vector:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.57      0.42      0.48        38\n",
            "        ENFP       0.70      0.59      0.64       135\n",
            "        ENTJ       0.64      0.39      0.49        46\n",
            "        ENTP       0.61      0.62      0.61       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.75      0.38      0.50         8\n",
            "        ESTP       0.42      0.28      0.33        18\n",
            "        INFJ       0.69      0.72      0.71       294\n",
            "        INFP       0.66      0.81      0.73       366\n",
            "        INTJ       0.65      0.64      0.65       218\n",
            "        INTP       0.70      0.79      0.74       261\n",
            "        ISFJ       0.59      0.48      0.53        33\n",
            "        ISFP       0.65      0.37      0.47        54\n",
            "        ISTJ       0.68      0.41      0.52        41\n",
            "        ISTP       0.66      0.55      0.60        67\n",
            "\n",
            "    accuracy                           0.67      1735\n",
            "   macro avg       0.62      0.47      0.51      1735\n",
            "weighted avg       0.66      0.67      0.65      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classifier 1: XGBoost Classifier\n",
        "# Use TF-IDF features + Trait Vector\n",
        "\n",
        "model_xgb_combined = xgb.XGBClassifier(tree_method='hist', device='cuda')\n",
        "model_xgb_combined.fit(train_combined, train_target)\n",
        "pred_combined = model_xgb_combined.predict(test_combined)\n",
        "print(\"Test accuracy score for XGBoost Classifier with TF-IDF Features+Trait Vector:\\n\", accuracy_score(test_target, pred_combined))\n",
        "print(\"Classification Report of XGBoost Classifier with TF-IDF Features+Trait Vector:\")\n",
        "print(classification_report(test_target, pred_combined, target_names=target_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 1: XGBoost Classifier\n",
        "# Use TF-IDF + Stylometric features\n",
        "model_xgb_stylo = xgb.XGBClassifier(tree_method='hist', device='cuda')\n",
        "model_xgb_stylo.fit(X_train_combined_stylo, train_target)\n",
        "pred_stylo = model_xgb_stylo.predict(X_test_combined_stylo)\n",
        "print(\"Test accuracy score for XGBoost Classifier with TF-IDF + stylometric features:\\n\", accuracy_score(test_target, pred_stylo))\n",
        "print(\"Classification Report for XGBoost Classifier with TF-IDF + stylometric features:\\n\")\n",
        "print(classification_report(test_target, pred_stylo, target_names=target_encoder.classes_, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7gR7tIIX3Oo",
        "outputId": "61df6437-bfa6-436f-db8e-0e57a85e5dad"
      },
      "id": "Y7gR7tIIX3Oo",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for XGBoost Classifier with TF-IDF + stylometric features:\n",
            " 0.6582132564841499\n",
            "Classification Report for XGBoost Classifier with TF-IDF + stylometric features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.61      0.45      0.52        38\n",
            "        ENFP       0.68      0.58      0.62       135\n",
            "        ENTJ       0.66      0.46      0.54        46\n",
            "        ENTP       0.58      0.59      0.59       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       1.00      0.38      0.55         8\n",
            "        ESTP       0.50      0.28      0.36        18\n",
            "        INFJ       0.67      0.70      0.69       294\n",
            "        INFP       0.66      0.80      0.72       366\n",
            "        INTJ       0.63      0.67      0.65       218\n",
            "        INTP       0.70      0.78      0.74       261\n",
            "        ISFJ       0.68      0.58      0.62        33\n",
            "        ISFP       0.65      0.37      0.47        54\n",
            "        ISTJ       0.67      0.39      0.49        41\n",
            "        ISTP       0.64      0.52      0.57        67\n",
            "\n",
            "    accuracy                           0.66      1735\n",
            "   macro avg       0.64      0.48      0.52      1735\n",
            "weighted avg       0.66      0.66      0.65      1735\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 1: XGBoost Classifier\n",
        "# Use TF-IDF + Stylometric features + Trait Vector\n",
        "model_xgb_all = xgb.XGBClassifier(tree_method='hist', device='cuda')\n",
        "model_xgb_all.fit(train_combined_stylo, train_target)\n",
        "pred_all = model_xgb_all.predict(test_combined_stylo)\n",
        "print(\"Test accuracy score for XGBoost with TF-IDF + Stylometric + trait vector features:\\n\", accuracy_score(test_target, pred_all))\n",
        "print(\"Classification Report for XGBoost with TF-IDF + Stylometric + trait vector features:\\n\")\n",
        "print(classification_report(test_target, pred_all, target_names=target_encoder.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCe0dU8Lf2Z5",
        "outputId": "9034bc9c-ca00-46ff-d511-74ed9d75e1c0"
      },
      "id": "pCe0dU8Lf2Z5",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for XGBoost with TF-IDF + Stylometric + trait vector features:\n",
            " 0.6639769452449568\n",
            "Classification Report for XGBoost with TF-IDF + Stylometric + trait vector features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.65      0.39      0.49        38\n",
            "        ENFP       0.71      0.63      0.67       135\n",
            "        ENTJ       0.66      0.41      0.51        46\n",
            "        ENTP       0.60      0.61      0.61       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       1.00      0.38      0.55         8\n",
            "        ESTP       0.45      0.28      0.34        18\n",
            "        INFJ       0.68      0.72      0.70       294\n",
            "        INFP       0.66      0.78      0.72       366\n",
            "        INTJ       0.63      0.66      0.64       218\n",
            "        INTP       0.71      0.77      0.74       261\n",
            "        ISFJ       0.67      0.48      0.56        33\n",
            "        ISFP       0.61      0.41      0.49        54\n",
            "        ISTJ       0.63      0.41      0.50        41\n",
            "        ISTP       0.65      0.60      0.62        67\n",
            "\n",
            "    accuracy                           0.66      1735\n",
            "   macro avg       0.64      0.48      0.52      1735\n",
            "weighted avg       0.66      0.66      0.66      1735\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "tuufQvZLSdgF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuufQvZLSdgF",
        "outputId": "0c145a74-c070-421d-ad71-57beceb5bfe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score  for LightGBM Classifier with TF-IDF Features Only:\n",
            " 0.6708933717579251\n",
            "Classification Report of LightGBM Classifier for TF-IDF Features Only:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.68      0.45      0.54        38\n",
            "        ENFP       0.70      0.62      0.66       135\n",
            "        ENTJ       0.68      0.33      0.44        46\n",
            "        ENTP       0.61      0.61      0.61       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.57      0.22      0.32        18\n",
            "        INFJ       0.67      0.75      0.71       294\n",
            "        INFP       0.65      0.80      0.72       366\n",
            "        INTJ       0.64      0.68      0.66       218\n",
            "        INTP       0.70      0.79      0.74       261\n",
            "        ISFJ       0.80      0.48      0.60        33\n",
            "        ISFP       0.76      0.48      0.59        54\n",
            "        ISTJ       0.72      0.32      0.44        41\n",
            "        ISTP       0.73      0.54      0.62        67\n",
            "\n",
            "    accuracy                           0.67      1735\n",
            "   macro avg       0.62      0.45      0.49      1735\n",
            "weighted avg       0.67      0.67      0.66      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Classifier 2: LightGBM Classifier\n",
        "# Use TF-IDF features only\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model_lgb_tfidf = lgb.LGBMClassifier(random_state=42, device='gpu',verbose=-1)\n",
        "model_lgb_tfidf.fit(train_post, train_target)\n",
        "pred_tfidf = model_lgb_tfidf.predict(test_post)\n",
        "print(\"Test accuracy score  for LightGBM Classifier with TF-IDF Features Only:\\n\", accuracy_score(test_target, pred_tfidf))\n",
        "print(\"Classification Report of LightGBM Classifier for TF-IDF Features Only:\")\n",
        "print(classification_report(test_target, pred_tfidf, target_names=target_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "HVuEK4c5Sh6g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVuEK4c5Sh6g",
        "outputId": "4fb66eed-9195-488e-ead6-5a77eb3775ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score  for LightGBM Classifier with TF-IDF Features+Trait Vector:\n",
            " 0.6657060518731989\n",
            "Classification Report of LightGBM Classifier with TF-IDF Features+Trait Vector:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.76      0.42      0.54        38\n",
            "        ENFP       0.69      0.63      0.66       135\n",
            "        ENTJ       0.64      0.35      0.45        46\n",
            "        ENTP       0.64      0.61      0.62       137\n",
            "        ESFJ       0.00      0.00      0.00         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.50      0.17      0.25        18\n",
            "        INFJ       0.67      0.75      0.71       294\n",
            "        INFP       0.65      0.82      0.73       366\n",
            "        INTJ       0.63      0.63      0.63       218\n",
            "        INTP       0.68      0.78      0.72       261\n",
            "        ISFJ       0.83      0.45      0.59        33\n",
            "        ISFP       0.76      0.46      0.57        54\n",
            "        ISTJ       0.75      0.37      0.49        41\n",
            "        ISTP       0.68      0.54      0.60        67\n",
            "\n",
            "    accuracy                           0.67      1735\n",
            "   macro avg       0.56      0.44      0.47      1735\n",
            "weighted avg       0.66      0.67      0.65      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Classifier 2: LightGBM Classifier\n",
        "# Use TF-IDF features + Trait Vector\n",
        "\n",
        "model_lgb_combined = lgb.LGBMClassifier(random_state=42, device='gpu',verbose=-1)\n",
        "model_lgb_combined.fit(train_combined, train_target)\n",
        "pred_combined = model_lgb_combined.predict(test_combined)\n",
        "print(\"Test accuracy score  for LightGBM Classifier with TF-IDF Features+Trait Vector:\\n\", accuracy_score(test_target, pred_combined))\n",
        "print(\"Classification Report of LightGBM Classifier with TF-IDF Features+Trait Vector:\")\n",
        "print(classification_report(test_target, pred_combined, target_names=target_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 2: LightGBM Classifier\n",
        "# Use TF-IDF + Stylometric features\n",
        "model_lgb_stylo = lgb.LGBMClassifier(random_state=42, device='gpu',verbose=-1)\n",
        "model_lgb_stylo.fit(X_train_combined_stylo, train_target)\n",
        "pred_stylo = model_lgb_stylo.predict(X_test_combined_stylo)\n",
        "print(\"Test accuracy score for LightGBM Classifier with TF-IDF + stylometric features:\\n\", accuracy_score(test_target, pred_stylo))\n",
        "print(\"Classification Report for LightGBM Classifier with TF-IDF + stylometric features:\\n\")\n",
        "print(classification_report(test_target, pred_stylo, target_names=target_encoder.classes_, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUsGQ5bmBDo",
        "outputId": "f93abb2c-f41e-41fb-b37f-e45b3ba93ef4"
      },
      "id": "ScUsGQ5bmBDo",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for LightGBM Classifier with TF-IDF + stylometric features:\n",
            " 0.6622478386167147\n",
            "Classification Report for LightGBM Classifier with TF-IDF + stylometric features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.71      0.45      0.55        38\n",
            "        ENFP       0.70      0.62      0.66       135\n",
            "        ENTJ       0.62      0.33      0.43        46\n",
            "        ENTP       0.62      0.61      0.61       137\n",
            "        ESFJ       1.00      0.22      0.36         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.57      0.22      0.32        18\n",
            "        INFJ       0.67      0.74      0.71       294\n",
            "        INFP       0.65      0.80      0.71       366\n",
            "        INTJ       0.63      0.66      0.64       218\n",
            "        INTP       0.68      0.78      0.73       261\n",
            "        ISFJ       0.75      0.45      0.57        33\n",
            "        ISFP       0.77      0.44      0.56        54\n",
            "        ISTJ       0.79      0.37      0.50        41\n",
            "        ISTP       0.67      0.51      0.58        67\n",
            "\n",
            "    accuracy                           0.66      1735\n",
            "   macro avg       0.61      0.45      0.50      1735\n",
            "weighted avg       0.66      0.66      0.65      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 2: LightGBM Classifier\n",
        "# Use TF-IDF + Stylometric features + Trait Vector\n",
        "model_lgb_all = lgb.LGBMClassifier(random_state=42, device='gpu',verbose=-1)\n",
        "model_lgb_all.fit(train_combined_stylo, train_target)\n",
        "pred_all = model_lgb_all.predict(test_combined_stylo)\n",
        "print(\"Test accuracy score for LightGBM Classifier with TF-IDF + Stylometric + trait vector features:\\n\", accuracy_score(test_target, pred_all))\n",
        "print(\"Classification Report for LightGBM Classifier with TF-IDF + Stylometric + trait vector features:\\n\")\n",
        "print(classification_report(test_target, pred_all, target_names=target_encoder.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "817bfCDPmBab",
        "outputId": "db8d2e55-df16-434a-82ac-80e68320070b"
      },
      "id": "817bfCDPmBab",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for LightGBM Classifier with TF-IDF + Stylometric + trait vector features:\n",
            " 0.6680115273775216\n",
            "Classification Report for LightGBM Classifier with TF-IDF + Stylometric + trait vector features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.71      0.39      0.51        38\n",
            "        ENFP       0.67      0.61      0.64       135\n",
            "        ENTJ       0.73      0.35      0.47        46\n",
            "        ENTP       0.66      0.63      0.64       137\n",
            "        ESFJ       1.00      0.22      0.36         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.60      0.17      0.26        18\n",
            "        INFJ       0.68      0.77      0.72       294\n",
            "        INFP       0.65      0.81      0.72       366\n",
            "        INTJ       0.62      0.64      0.63       218\n",
            "        INTP       0.69      0.79      0.73       261\n",
            "        ISFJ       0.76      0.39      0.52        33\n",
            "        ISFP       0.75      0.44      0.56        54\n",
            "        ISTJ       0.76      0.39      0.52        41\n",
            "        ISTP       0.67      0.54      0.60        67\n",
            "\n",
            "    accuracy                           0.67      1735\n",
            "   macro avg       0.62      0.45      0.49      1735\n",
            "weighted avg       0.67      0.67      0.66      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ohDvAvqYTFBW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohDvAvqYTFBW",
        "outputId": "85d43038-7508-4f3d-ae8a-5efa98879f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for model trained on Logistic Regression for TF-IDF Features Only:\n",
            " 0.6495677233429394\n",
            "Classification Report of Logistic Regression Classifier for TF-IDF Features Only:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.64      0.18      0.29        38\n",
            "        ENFP       0.75      0.59      0.66       135\n",
            "        ENTJ       0.60      0.26      0.36        46\n",
            "        ENTP       0.66      0.53      0.59       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       1.00      0.11      0.20        18\n",
            "        INFJ       0.65      0.71      0.68       294\n",
            "        INFP       0.60      0.86      0.71       366\n",
            "        INTJ       0.62      0.67      0.64       218\n",
            "        INTP       0.68      0.84      0.75       261\n",
            "        ISFJ       0.67      0.18      0.29        33\n",
            "        ISFP       0.80      0.30      0.43        54\n",
            "        ISTJ       0.75      0.22      0.34        41\n",
            "        ISTP       0.69      0.52      0.59        67\n",
            "\n",
            "    accuracy                           0.65      1735\n",
            "   macro avg       0.63      0.38      0.42      1735\n",
            "weighted avg       0.66      0.65      0.63      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classifier 3: Logistic Regression Classifier\n",
        "# Use TF-IDF features only\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model_lr_tfidf = LogisticRegression()\n",
        "model_lr_tfidf.fit(train_post, train_target)\n",
        "pred_tfidf = model_lr_tfidf.predict(test_post)\n",
        "\n",
        "print(\"Test accuracy score for model trained on Logistic Regression for TF-IDF Features Only:\\n\",\n",
        "      accuracy_score(test_target, pred_tfidf))\n",
        "print(\"Classification Report of Logistic Regression Classifier for TF-IDF Features Only:\")\n",
        "print(classification_report(test_target, pred_tfidf, target_names=target_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5q3-PGH7TKxN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q3-PGH7TKxN",
        "outputId": "f295a6de-b0b7-43df-ba31-dec07b4b593a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for model trained on Logistic Regression TF-IDF Features + Trait Vector:\n",
            " 0.6495677233429394\n",
            "Classification Report of Logistic Regression Classifier for TF-IDF Features + Trait Vector:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.64      0.18      0.29        38\n",
            "        ENFP       0.75      0.59      0.66       135\n",
            "        ENTJ       0.60      0.26      0.36        46\n",
            "        ENTP       0.66      0.53      0.59       137\n",
            "        ESFJ       1.00      0.11      0.20         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       1.00      0.11      0.20        18\n",
            "        INFJ       0.66      0.71      0.68       294\n",
            "        INFP       0.60      0.86      0.71       366\n",
            "        INTJ       0.62      0.67      0.64       218\n",
            "        INTP       0.68      0.84      0.75       261\n",
            "        ISFJ       0.67      0.18      0.29        33\n",
            "        ISFP       0.80      0.30      0.43        54\n",
            "        ISTJ       0.75      0.22      0.34        41\n",
            "        ISTP       0.69      0.52      0.59        67\n",
            "\n",
            "    accuracy                           0.65      1735\n",
            "   macro avg       0.63      0.38      0.42      1735\n",
            "weighted avg       0.66      0.65      0.63      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classifier 3: Logistic Regression Classifier\n",
        "# Use TF-IDF features + Trait Vector\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model_lr_combined = LogisticRegression()\n",
        "model_lr_combined.fit(train_combined, train_target)\n",
        "pred_combined = model_lr_combined.predict(test_combined)\n",
        "\n",
        "print(\"Test accuracy score for model trained on Logistic Regression TF-IDF Features + Trait Vector:\\n\",\n",
        "      accuracy_score(test_target, pred_combined))\n",
        "print(\"Classification Report of Logistic Regression Classifier for TF-IDF Features + Trait Vector:\")\n",
        "print(classification_report(test_target, pred_combined, target_names=target_encoder.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 3: Logistic Regression Classifier\n",
        "# Use TF-IDF + Stylometric features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model_lr_stylo = LogisticRegression()\n",
        "model_lr_stylo.fit(X_train_combined_stylo, train_target)\n",
        "pred_stylo = model_lr_stylo.predict(X_test_combined_stylo)\n",
        "print(\"Test accuracy score for Logistic Regression Classifier with TF-IDF + stylometric features:\\n\", accuracy_score(test_target, pred_stylo))\n",
        "print(\"Classification Report for Logistic Regression Classifier with TF-IDF + stylometric features:\\n\")\n",
        "print(classification_report(test_target, pred_stylo, target_names=target_encoder.classes_, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-4wwHzdn8yO",
        "outputId": "0c141e9b-6ee7-485d-f7d1-fb8d749fc341"
      },
      "id": "v-4wwHzdn8yO",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for Logistic Regression Classifier with TF-IDF + stylometric features:\n",
            " 0.2195965417867435\n",
            "Classification Report for Logistic Regression Classifier with TF-IDF + stylometric features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.00      0.00      0.00        38\n",
            "        ENFP       0.07      0.02      0.03       135\n",
            "        ENTJ       0.00      0.00      0.00        46\n",
            "        ENTP       0.00      0.00      0.00       137\n",
            "        ESFJ       0.00      0.00      0.00         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.00      0.00      0.00        18\n",
            "        INFJ       0.00      0.00      0.00       294\n",
            "        INFP       0.22      0.86      0.35       366\n",
            "        INTJ       0.24      0.06      0.09       218\n",
            "        INTP       0.23      0.19      0.21       261\n",
            "        ISFJ       0.00      0.00      0.00        33\n",
            "        ISFP       0.00      0.00      0.00        54\n",
            "        ISTJ       0.00      0.00      0.00        41\n",
            "        ISTP       0.00      0.00      0.00        67\n",
            "\n",
            "    accuracy                           0.22      1735\n",
            "   macro avg       0.05      0.07      0.04      1735\n",
            "weighted avg       0.12      0.22      0.12      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 3: Logistic Regression Classifier\n",
        "# Use TF-IDF + Stylometric features + Trait Vector\n",
        "model_lr_all = LogisticRegression()\n",
        "model_lr_all.fit(train_combined_stylo, train_target)\n",
        "pred_all = model_lr_all.predict(test_combined_stylo)\n",
        "print(\"Test accuracy score for Logistic Regression Classifier with TF-IDF + Stylometric + trait vector features:\\n\", accuracy_score(test_target, pred_all))\n",
        "print(\"Classification Report for Logistic Regression Classifier with TF-IDF + Stylometric + trait vector features:\\n\")\n",
        "print(classification_report(test_target, pred_all, target_names=target_encoder.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvLireZmn9bU",
        "outputId": "153a4e11-9cf1-4e2f-f3f2-19edf1898648"
      },
      "id": "VvLireZmn9bU",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score for Logistic Regression Classifier with TF-IDF + Stylometric + trait vector features:\n",
            " 0.21671469740634006\n",
            "Classification Report for Logistic Regression Classifier with TF-IDF + Stylometric + trait vector features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.00      0.00      0.00        38\n",
            "        ENFP       0.08      0.02      0.03       135\n",
            "        ENTJ       0.00      0.00      0.00        46\n",
            "        ENTP       0.00      0.00      0.00       137\n",
            "        ESFJ       0.00      0.00      0.00         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.00      0.00      0.00        18\n",
            "        INFJ       0.00      0.00      0.00       294\n",
            "        INFP       0.22      0.87      0.35       366\n",
            "        INTJ       0.23      0.06      0.09       218\n",
            "        INTP       0.23      0.16      0.19       261\n",
            "        ISFJ       0.00      0.00      0.00        33\n",
            "        ISFP       0.00      0.00      0.00        54\n",
            "        ISTJ       0.00      0.00      0.00        41\n",
            "        ISTP       0.00      0.00      0.00        67\n",
            "\n",
            "    accuracy                           0.22      1735\n",
            "   macro avg       0.05      0.07      0.04      1735\n",
            "weighted avg       0.12      0.22      0.12      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 4: Support Vector Classifier\n",
        "# Use TF-IDF features only\n",
        "from cuml.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "model_svc_tfidf = SVC(random_state=42)\n",
        "model_svc_tfidf.fit(train_post, train_target)\n",
        "pred_tfidf = model_svc_tfidf.predict(test_post)\n",
        "pred_training_tfidf = model_svc_tfidf.predict(train_post)\n",
        "\n",
        "print(\"Test accuracy score for model trained on Support Vector Classifier TF-IDF Features Only:\\n\",\n",
        "      accuracy_score(test_target, pred_tfidf))\n",
        "print(\"Test classification report of Support Vector Classifier for TF-IDF Features Only:\",\n",
        "      classification_report(test_target, pred_tfidf, target_names=target_encoder.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSc7pF77OXoa",
        "outputId": "cb745833-8729-47c6-ec1c-c6107826d6b7"
      },
      "id": "wSc7pF77OXoa",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-27 10:18:08.692] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 10:18:08.696] [CUML] [warning] Warning: could not fill working set, found only 1002 elements\n",
            "[2025-05-27 10:18:08.698] [CUML] [warning] Warning: could not fill working set, found only 858 elements\n",
            "[2025-05-27 10:18:08.702] [CUML] [warning] Warning: could not fill working set, found only 995 elements\n",
            "[2025-05-27 10:18:08.705] [CUML] [warning] Warning: could not fill working set, found only 779 elements\n",
            "[2025-05-27 10:18:08.706] [CUML] [warning] Warning: could not fill working set, found only 997 elements\n",
            "[2025-05-27 10:18:08.800] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 10:18:08.804] [CUML] [warning] Warning: could not fill working set, found only 1008 elements\n",
            "[2025-05-27 10:18:08.807] [CUML] [warning] Warning: could not fill working set, found only 866 elements\n",
            "[2025-05-27 10:18:08.810] [CUML] [warning] Warning: could not fill working set, found only 1008 elements\n",
            "[2025-05-27 10:18:08.813] [CUML] [warning] Warning: could not fill working set, found only 825 elements\n",
            "[2025-05-27 10:18:08.815] [CUML] [warning] Warning: could not fill working set, found only 1007 elements\n",
            "[2025-05-27 10:18:08.884] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 10:18:08.888] [CUML] [warning] Warning: could not fill working set, found only 864 elements\n",
            "[2025-05-27 10:18:08.890] [CUML] [warning] Warning: could not fill working set, found only 796 elements\n",
            "[2025-05-27 10:18:08.893] [CUML] [warning] Warning: could not fill working set, found only 840 elements\n",
            "[2025-05-27 10:18:08.894] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 10:18:08.972] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 10:18:08.975] [CUML] [warning] Warning: could not fill working set, found only 958 elements\n",
            "[2025-05-27 10:18:08.978] [CUML] [warning] Warning: could not fill working set, found only 796 elements\n",
            "[2025-05-27 10:18:08.981] [CUML] [warning] Warning: could not fill working set, found only 901 elements\n",
            "[2025-05-27 10:18:08.983] [CUML] [warning] Warning: could not fill working set, found only 780 elements\n",
            "[2025-05-27 10:18:09.263] [CUML] [warning] Warning: could not fill working set, found only 984 elements\n",
            "[2025-05-27 10:18:09.265] [CUML] [warning] Warning: could not fill working set, found only 922 elements\n",
            "[2025-05-27 10:18:09.268] [CUML] [warning] Warning: could not fill working set, found only 970 elements\n",
            "[2025-05-27 10:18:09.270] [CUML] [warning] Warning: could not fill working set, found only 911 elements\n",
            "[2025-05-27 10:18:09.272] [CUML] [warning] Warning: could not fill working set, found only 968 elements\n",
            "[2025-05-27 10:18:10.490] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 10:18:10.494] [CUML] [warning] Warning: could not fill working set, found only 1010 elements\n",
            "[2025-05-27 10:18:10.497] [CUML] [warning] Warning: could not fill working set, found only 799 elements\n",
            "[2025-05-27 10:18:10.500] [CUML] [warning] Warning: could not fill working set, found only 973 elements\n",
            "[2025-05-27 10:18:10.502] [CUML] [warning] Warning: could not fill working set, found only 781 elements\n",
            "[2025-05-27 10:18:10.597] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 10:18:10.601] [CUML] [warning] Warning: could not fill working set, found only 996 elements\n",
            "[2025-05-27 10:18:10.604] [CUML] [warning] Warning: could not fill working set, found only 834 elements\n",
            "[2025-05-27 10:18:10.607] [CUML] [warning] Warning: could not fill working set, found only 1004 elements\n",
            "[2025-05-27 10:18:10.610] [CUML] [warning] Warning: could not fill working set, found only 778 elements\n",
            "[2025-05-27 10:18:10.611] [CUML] [warning] Warning: could not fill working set, found only 1003 elements\n",
            "[2025-05-27 10:18:10.681] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 10:18:10.685] [CUML] [warning] Warning: could not fill working set, found only 915 elements\n",
            "[2025-05-27 10:18:10.687] [CUML] [warning] Warning: could not fill working set, found only 810 elements\n",
            "[2025-05-27 10:18:10.690] [CUML] [warning] Warning: could not fill working set, found only 895 elements\n",
            "[2025-05-27 10:18:10.692] [CUML] [warning] Warning: could not fill working set, found only 800 elements\n",
            "[2025-05-27 10:18:10.767] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 10:18:10.774] [CUML] [warning] Warning: could not fill working set, found only 812 elements\n",
            "[2025-05-27 10:18:10.777] [CUML] [warning] Warning: could not fill working set, found only 989 elements\n",
            "[2025-05-27 10:18:10.779] [CUML] [warning] Warning: could not fill working set, found only 779 elements\n",
            "[2025-05-27 10:18:11.471] [CUML] [warning] Warning: could not fill working set, found only 1019 elements\n",
            "[2025-05-27 10:18:11.961] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 10:18:11.964] [CUML] [warning] Warning: could not fill working set, found only 824 elements\n",
            "[2025-05-27 10:18:11.966] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 10:18:11.969] [CUML] [warning] Warning: could not fill working set, found only 815 elements\n",
            "[2025-05-27 10:18:11.971] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 10:18:12.059] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 10:18:12.061] [CUML] [warning] Warning: could not fill working set, found only 830 elements\n",
            "[2025-05-27 10:18:12.064] [CUML] [warning] Warning: could not fill working set, found only 770 elements\n",
            "[2025-05-27 10:18:12.067] [CUML] [warning] Warning: could not fill working set, found only 864 elements\n",
            "[2025-05-27 10:18:12.069] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 10:18:12.204] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 10:18:12.206] [CUML] [warning] Warning: could not fill working set, found only 830 elements\n",
            "[2025-05-27 10:18:12.208] [CUML] [warning] Warning: could not fill working set, found only 778 elements\n",
            "[2025-05-27 10:18:12.210] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 10:18:12.212] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 10:18:12.429] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 10:18:12.431] [CUML] [warning] Warning: could not fill working set, found only 853 elements\n",
            "[2025-05-27 10:18:12.434] [CUML] [warning] Warning: could not fill working set, found only 810 elements\n",
            "[2025-05-27 10:18:12.437] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 10:18:12.439] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 10:18:12.525] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 10:18:12.527] [CUML] [warning] Warning: could not fill working set, found only 851 elements\n",
            "[2025-05-27 10:18:12.530] [CUML] [warning] Warning: could not fill working set, found only 802 elements\n",
            "[2025-05-27 10:18:12.532] [CUML] [warning] Warning: could not fill working set, found only 915 elements\n",
            "[2025-05-27 10:18:12.535] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 10:18:12.675] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 10:18:12.677] [CUML] [warning] Warning: could not fill working set, found only 843 elements\n",
            "[2025-05-27 10:18:12.680] [CUML] [warning] Warning: could not fill working set, found only 819 elements\n",
            "[2025-05-27 10:18:12.682] [CUML] [warning] Warning: could not fill working set, found only 809 elements\n",
            "[2025-05-27 10:18:12.684] [CUML] [warning] Warning: could not fill working set, found only 771 elements\n",
            "[2025-05-27 10:18:12.883] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 10:18:12.886] [CUML] [warning] Warning: could not fill working set, found only 833 elements\n",
            "[2025-05-27 10:18:12.888] [CUML] [warning] Warning: could not fill working set, found only 775 elements\n",
            "[2025-05-27 10:18:12.891] [CUML] [warning] Warning: could not fill working set, found only 818 elements\n",
            "[2025-05-27 10:18:12.893] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 10:18:12.981] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 10:18:12.984] [CUML] [warning] Warning: could not fill working set, found only 833 elements\n",
            "[2025-05-27 10:18:12.986] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 10:18:12.989] [CUML] [warning] Warning: could not fill working set, found only 910 elements\n",
            "[2025-05-27 10:18:12.991] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 10:18:13.127] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 10:18:13.129] [CUML] [warning] Warning: could not fill working set, found only 831 elements\n",
            "[2025-05-27 10:18:13.132] [CUML] [warning] Warning: could not fill working set, found only 792 elements\n",
            "[2025-05-27 10:18:13.134] [CUML] [warning] Warning: could not fill working set, found only 820 elements\n",
            "[2025-05-27 10:18:13.136] [CUML] [warning] Warning: could not fill working set, found only 771 elements\n",
            "[2025-05-27 10:18:13.318] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 10:18:13.321] [CUML] [warning] Warning: could not fill working set, found only 895 elements\n",
            "[2025-05-27 10:18:13.323] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 10:18:13.326] [CUML] [warning] Warning: could not fill working set, found only 837 elements\n",
            "[2025-05-27 10:18:13.328] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 10:18:13.418] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 10:18:13.421] [CUML] [warning] Warning: could not fill working set, found only 898 elements\n",
            "[2025-05-27 10:18:13.424] [CUML] [warning] Warning: could not fill working set, found only 770 elements\n",
            "[2025-05-27 10:18:13.427] [CUML] [warning] Warning: could not fill working set, found only 924 elements\n",
            "[2025-05-27 10:18:13.429] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 10:18:13.572] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 10:18:13.575] [CUML] [warning] Warning: could not fill working set, found only 894 elements\n",
            "[2025-05-27 10:18:13.577] [CUML] [warning] Warning: could not fill working set, found only 798 elements\n",
            "[2025-05-27 10:18:13.580] [CUML] [warning] Warning: could not fill working set, found only 847 elements\n",
            "[2025-05-27 10:18:13.582] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "Test accuracy score for model trained on Support Vector Classifier (TF-IDF only):\n",
            " 0.6512968299711815\n",
            "Test classification report of Support Vector Classifier for TF-IDF Features Only:               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.67      0.26      0.38        38\n",
            "        ENFP       0.77      0.57      0.66       135\n",
            "        ENTJ       0.75      0.26      0.39        46\n",
            "        ENTP       0.68      0.52      0.59       137\n",
            "        ESFJ       0.33      0.11      0.17         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.80      0.22      0.35        18\n",
            "        INFJ       0.67      0.69      0.68       294\n",
            "        INFP       0.59      0.86      0.70       366\n",
            "        INTJ       0.65      0.64      0.65       218\n",
            "        INTP       0.65      0.84      0.74       261\n",
            "        ISFJ       0.83      0.30      0.44        33\n",
            "        ISFP       0.78      0.33      0.47        54\n",
            "        ISTJ       0.75      0.29      0.42        41\n",
            "        ISTP       0.76      0.57      0.65        67\n",
            "\n",
            "    accuracy                           0.65      1735\n",
            "   macro avg       0.61      0.40      0.45      1735\n",
            "weighted avg       0.66      0.65      0.63      1735\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 4: Support Vector Classifier\n",
        "# Use TF-IDF features + Trait Vector\n",
        "model_svc_combined = SVC(random_state=42, verbose=False)\n",
        "model_svc_combined.fit(train_combined, train_target)\n",
        "pred_combined = model_svc_combined.predict(test_combined)\n",
        "pred_training_combined = model_svc_combined.predict(train_combined)\n",
        "\n",
        "print(\"Test accuracy score for model trained on Support Vector Classifier with TF-IDF Features + Trait Vector:\",\n",
        "      accuracy_score(test_target, pred_combined))\n",
        "\n",
        "print(\"Test classification report of Support Vector Classifier with TF-IDF Features + Trait Vector:\\n\",\n",
        "      classification_report(test_target, pred_combined, target_names=target_encoder.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e11g_hR3QB_T",
        "outputId": "776178a0-d922-496b-f4d9-3e720cd0252e"
      },
      "id": "e11g_hR3QB_T",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-27 12:31:55.312] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:31:55.316] [CUML] [warning] Warning: could not fill working set, found only 984 elements\n",
            "[2025-05-27 12:31:55.318] [CUML] [warning] Warning: could not fill working set, found only 833 elements\n",
            "[2025-05-27 12:31:55.321] [CUML] [warning] Warning: could not fill working set, found only 967 elements\n",
            "[2025-05-27 12:31:55.324] [CUML] [warning] Warning: could not fill working set, found only 775 elements\n",
            "[2025-05-27 12:31:55.325] [CUML] [warning] Warning: could not fill working set, found only 967 elements\n",
            "[2025-05-27 12:31:55.419] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:31:55.422] [CUML] [warning] Warning: could not fill working set, found only 990 elements\n",
            "[2025-05-27 12:31:55.425] [CUML] [warning] Warning: could not fill working set, found only 853 elements\n",
            "[2025-05-27 12:31:55.428] [CUML] [warning] Warning: could not fill working set, found only 993 elements\n",
            "[2025-05-27 12:31:55.431] [CUML] [warning] Warning: could not fill working set, found only 771 elements\n",
            "[2025-05-27 12:31:55.433] [CUML] [warning] Warning: could not fill working set, found only 993 elements\n",
            "[2025-05-27 12:31:55.497] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:31:55.501] [CUML] [warning] Warning: could not fill working set, found only 856 elements\n",
            "[2025-05-27 12:31:55.503] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:31:55.506] [CUML] [warning] Warning: could not fill working set, found only 815 elements\n",
            "[2025-05-27 12:31:55.507] [CUML] [warning] Warning: could not fill working set, found only 785 elements\n",
            "[2025-05-27 12:31:55.585] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:31:55.588] [CUML] [warning] Warning: could not fill working set, found only 932 elements\n",
            "[2025-05-27 12:31:55.590] [CUML] [warning] Warning: could not fill working set, found only 785 elements\n",
            "[2025-05-27 12:31:55.593] [CUML] [warning] Warning: could not fill working set, found only 865 elements\n",
            "[2025-05-27 12:31:55.595] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:31:55.859] [CUML] [warning] Warning: could not fill working set, found only 974 elements\n",
            "[2025-05-27 12:31:55.860] [CUML] [warning] Warning: could not fill working set, found only 919 elements\n",
            "[2025-05-27 12:31:55.863] [CUML] [warning] Warning: could not fill working set, found only 950 elements\n",
            "[2025-05-27 12:31:55.865] [CUML] [warning] Warning: could not fill working set, found only 898 elements\n",
            "[2025-05-27 12:31:55.867] [CUML] [warning] Warning: could not fill working set, found only 950 elements\n",
            "[2025-05-27 12:31:56.409] [CUML] [warning] Warning: could not fill working set, found only 972 elements\n",
            "[2025-05-27 12:31:56.411] [CUML] [warning] Warning: could not fill working set, found only 1023 elements\n",
            "[2025-05-27 12:31:56.520] [CUML] [warning] Warning: could not fill working set, found only 1015 elements\n",
            "[2025-05-27 12:31:57.005] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:31:57.008] [CUML] [warning] Warning: could not fill working set, found only 979 elements\n",
            "[2025-05-27 12:31:57.011] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:31:57.014] [CUML] [warning] Warning: could not fill working set, found only 939 elements\n",
            "[2025-05-27 12:31:57.016] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:31:57.112] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:31:57.116] [CUML] [warning] Warning: could not fill working set, found only 981 elements\n",
            "[2025-05-27 12:31:57.119] [CUML] [warning] Warning: could not fill working set, found only 819 elements\n",
            "[2025-05-27 12:31:57.122] [CUML] [warning] Warning: could not fill working set, found only 973 elements\n",
            "[2025-05-27 12:31:57.124] [CUML] [warning] Warning: could not fill working set, found only 781 elements\n",
            "[2025-05-27 12:31:57.126] [CUML] [warning] Warning: could not fill working set, found only 972 elements\n",
            "[2025-05-27 12:31:57.191] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:31:57.195] [CUML] [warning] Warning: could not fill working set, found only 889 elements\n",
            "[2025-05-27 12:31:57.197] [CUML] [warning] Warning: could not fill working set, found only 797 elements\n",
            "[2025-05-27 12:31:57.199] [CUML] [warning] Warning: could not fill working set, found only 873 elements\n",
            "[2025-05-27 12:31:57.202] [CUML] [warning] Warning: could not fill working set, found only 780 elements\n",
            "[2025-05-27 12:31:57.278] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:31:57.281] [CUML] [warning] Warning: could not fill working set, found only 1000 elements\n",
            "[2025-05-27 12:31:57.284] [CUML] [warning] Warning: could not fill working set, found only 795 elements\n",
            "[2025-05-27 12:31:57.287] [CUML] [warning] Warning: could not fill working set, found only 948 elements\n",
            "[2025-05-27 12:31:57.289] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:31:57.969] [CUML] [warning] Warning: could not fill working set, found only 975 elements\n",
            "[2025-05-27 12:31:58.442] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:31:58.445] [CUML] [warning] Warning: could not fill working set, found only 823 elements\n",
            "[2025-05-27 12:31:58.447] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:31:58.449] [CUML] [warning] Warning: could not fill working set, found only 780 elements\n",
            "[2025-05-27 12:31:58.451] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:58.542] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:31:58.544] [CUML] [warning] Warning: could not fill working set, found only 824 elements\n",
            "[2025-05-27 12:31:58.547] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:31:58.549] [CUML] [warning] Warning: could not fill working set, found only 827 elements\n",
            "[2025-05-27 12:31:58.551] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:31:58.688] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:31:58.690] [CUML] [warning] Warning: could not fill working set, found only 822 elements\n",
            "[2025-05-27 12:31:58.692] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:58.694] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:31:58.696] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:58.977] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:31:58.979] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:31:58.982] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:31:58.984] [CUML] [warning] Warning: could not fill working set, found only 821 elements\n",
            "[2025-05-27 12:31:58.986] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.072] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:31:59.074] [CUML] [warning] Warning: could not fill working set, found only 847 elements\n",
            "[2025-05-27 12:31:59.077] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:31:59.079] [CUML] [warning] Warning: could not fill working set, found only 878 elements\n",
            "[2025-05-27 12:31:59.081] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.221] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:31:59.224] [CUML] [warning] Warning: could not fill working set, found only 840 elements\n",
            "[2025-05-27 12:31:59.226] [CUML] [warning] Warning: could not fill working set, found only 796 elements\n",
            "[2025-05-27 12:31:59.228] [CUML] [warning] Warning: could not fill working set, found only 779 elements\n",
            "[2025-05-27 12:31:59.230] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.477] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:31:59.479] [CUML] [warning] Warning: could not fill working set, found only 829 elements\n",
            "[2025-05-27 12:31:59.482] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.484] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:31:59.486] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.576] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:31:59.578] [CUML] [warning] Warning: could not fill working set, found only 830 elements\n",
            "[2025-05-27 12:31:59.580] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:31:59.583] [CUML] [warning] Warning: could not fill working set, found only 879 elements\n",
            "[2025-05-27 12:31:59.585] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.721] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:31:59.724] [CUML] [warning] Warning: could not fill working set, found only 828 elements\n",
            "[2025-05-27 12:31:59.726] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:31:59.729] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:31:59.730] [CUML] [warning] Warning: could not fill working set, found only 768 elements\n",
            "[2025-05-27 12:31:59.955] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:31:59.957] [CUML] [warning] Warning: could not fill working set, found only 879 elements\n",
            "[2025-05-27 12:31:59.960] [CUML] [warning] Warning: could not fill working set, found only 770 elements\n",
            "[2025-05-27 12:31:59.962] [CUML] [warning] Warning: could not fill working set, found only 807 elements\n",
            "[2025-05-27 12:31:59.964] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:32:00.057] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:32:00.060] [CUML] [warning] Warning: could not fill working set, found only 888 elements\n",
            "[2025-05-27 12:32:00.063] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:32:00.065] [CUML] [warning] Warning: could not fill working set, found only 897 elements\n",
            "[2025-05-27 12:32:00.067] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "[2025-05-27 12:32:00.202] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:32:00.205] [CUML] [warning] Warning: could not fill working set, found only 880 elements\n",
            "[2025-05-27 12:32:00.207] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:32:00.209] [CUML] [warning] Warning: could not fill working set, found only 820 elements\n",
            "[2025-05-27 12:32:00.212] [CUML] [warning] Warning: could not fill working set, found only 769 elements\n",
            "Test accuracy score for model trained on Support Vector Classifier (Combined features): 0.6547550432276658\n",
            "Test classification report of Support Vector Classifier for TF-IDF Features + Trait Vector:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.69      0.29      0.41        38\n",
            "        ENFP       0.76      0.58      0.66       135\n",
            "        ENTJ       0.72      0.28      0.41        46\n",
            "        ENTP       0.68      0.53      0.59       137\n",
            "        ESFJ       0.33      0.11      0.17         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.83      0.28      0.42        18\n",
            "        INFJ       0.67      0.70      0.69       294\n",
            "        INFP       0.59      0.86      0.70       366\n",
            "        INTJ       0.65      0.64      0.65       218\n",
            "        INTP       0.65      0.84      0.74       261\n",
            "        ISFJ       0.83      0.30      0.44        33\n",
            "        ISFP       0.78      0.33      0.47        54\n",
            "        ISTJ       0.75      0.29      0.42        41\n",
            "        ISTP       0.76      0.57      0.65        67\n",
            "\n",
            "    accuracy                           0.65      1735\n",
            "   macro avg       0.61      0.41      0.46      1735\n",
            "weighted avg       0.66      0.65      0.64      1735\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 4: Support Vector Classifier\n",
        "# Use TF-IDF + Stylometric features\n",
        "model_svc_stylo = SVC(random_state=42)\n",
        "model_svc_stylo.fit(X_train_combined_stylo, train_target)\n",
        "pred_stylo = model_lgb_stylo.predict(X_test_combined_stylo)\n",
        "print(\"Test accuracy score for Support Vector Classifier with TF-IDF + stylometric features:\\n\", accuracy_score(test_target, pred_stylo))\n",
        "print(\"Classification Report for Support Vector Classifier with TF-IDF + stylometric features:\\n\")\n",
        "print(classification_report(test_target, pred_stylo, target_names=target_encoder.classes_, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxbMJO8YrduJ",
        "outputId": "2e01d518-8b77-44c1-dae2-21ac07ba5fcd"
      },
      "id": "wxbMJO8YrduJ",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-27 12:19:53.039] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:19:53.041] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 12:19:53.043] [CUML] [warning] Warning: could not fill working set, found only 831 elements\n",
            "[2025-05-27 12:19:53.044] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 12:19:53.137] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:19:53.140] [CUML] [warning] Warning: could not fill working set, found only 865 elements\n",
            "[2025-05-27 12:19:53.141] [CUML] [warning] Warning: could not fill working set, found only 827 elements\n",
            "[2025-05-27 12:19:53.143] [CUML] [warning] Warning: could not fill working set, found only 865 elements\n",
            "[2025-05-27 12:19:53.212] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:19:53.215] [CUML] [warning] Warning: could not fill working set, found only 845 elements\n",
            "[2025-05-27 12:19:53.216] [CUML] [warning] Warning: could not fill working set, found only 843 elements\n",
            "[2025-05-27 12:19:53.218] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:19:53.220] [CUML] [warning] Warning: could not fill working set, found only 837 elements\n",
            "[2025-05-27 12:19:53.297] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:19:53.300] [CUML] [warning] Warning: could not fill working set, found only 859 elements\n",
            "[2025-05-27 12:19:53.301] [CUML] [warning] Warning: could not fill working set, found only 831 elements\n",
            "[2025-05-27 12:19:53.303] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 12:19:53.304] [CUML] [warning] Warning: could not fill working set, found only 836 elements\n",
            "[2025-05-27 12:19:53.576] [CUML] [warning] Warning: could not fill working set, found only 832 elements\n",
            "[2025-05-27 12:19:53.578] [CUML] [warning] Warning: could not fill working set, found only 896 elements\n",
            "[2025-05-27 12:19:53.885] [CUML] [warning] Warning: could not fill working set, found only 1016 elements\n",
            "[2025-05-27 12:19:54.693] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:19:54.696] [CUML] [warning] Warning: could not fill working set, found only 878 elements\n",
            "[2025-05-27 12:19:54.697] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:19:54.699] [CUML] [warning] Warning: could not fill working set, found only 878 elements\n",
            "[2025-05-27 12:19:54.700] [CUML] [warning] Warning: could not fill working set, found only 843 elements\n",
            "[2025-05-27 12:19:54.795] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:19:54.798] [CUML] [warning] Warning: could not fill working set, found only 882 elements\n",
            "[2025-05-27 12:19:54.799] [CUML] [warning] Warning: could not fill working set, found only 841 elements\n",
            "[2025-05-27 12:19:54.801] [CUML] [warning] Warning: could not fill working set, found only 886 elements\n",
            "[2025-05-27 12:19:54.871] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:19:54.873] [CUML] [warning] Warning: could not fill working set, found only 875 elements\n",
            "[2025-05-27 12:19:54.875] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:19:54.877] [CUML] [warning] Warning: could not fill working set, found only 876 elements\n",
            "[2025-05-27 12:19:54.953] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:19:54.955] [CUML] [warning] Warning: could not fill working set, found only 880 elements\n",
            "[2025-05-27 12:19:54.957] [CUML] [warning] Warning: could not fill working set, found only 842 elements\n",
            "[2025-05-27 12:19:54.959] [CUML] [warning] Warning: could not fill working set, found only 879 elements\n",
            "[2025-05-27 12:19:56.124] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:19:56.126] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:19:56.127] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:19:56.129] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:19:56.130] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:19:56.219] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:19:56.221] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:19:56.223] [CUML] [warning] Warning: could not fill working set, found only 780 elements\n",
            "[2025-05-27 12:19:56.225] [CUML] [warning] Warning: could not fill working set, found only 803 elements\n",
            "[2025-05-27 12:19:56.363] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:19:56.365] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:19:56.367] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:19:56.369] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:19:56.587] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:19:56.589] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:19:56.591] [CUML] [warning] Warning: could not fill working set, found only 789 elements\n",
            "[2025-05-27 12:19:56.592] [CUML] [warning] Warning: could not fill working set, found only 789 elements\n",
            "[2025-05-27 12:19:56.593] [CUML] [warning] Warning: could not fill working set, found only 789 elements\n",
            "[2025-05-27 12:19:56.679] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:19:56.681] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:19:56.683] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:19:56.684] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:19:56.686] [CUML] [warning] Warning: could not fill working set, found only 792 elements\n",
            "[2025-05-27 12:19:56.822] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:19:56.824] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:19:56.825] [CUML] [warning] Warning: could not fill working set, found only 792 elements\n",
            "[2025-05-27 12:19:56.828] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:19:57.034] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:19:57.036] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:19:57.038] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:19:57.039] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:19:57.041] [CUML] [warning] Warning: could not fill working set, found only 793 elements\n",
            "[2025-05-27 12:19:57.130] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:19:57.132] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:19:57.133] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:19:57.135] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:19:57.136] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:19:57.274] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:19:57.276] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:19:57.277] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:19:57.279] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:19:57.280] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:19:57.467] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:19:57.469] [CUML] [warning] Warning: could not fill working set, found only 805 elements\n",
            "[2025-05-27 12:19:57.470] [CUML] [warning] Warning: could not fill working set, found only 804 elements\n",
            "[2025-05-27 12:19:57.472] [CUML] [warning] Warning: could not fill working set, found only 805 elements\n",
            "[2025-05-27 12:19:57.473] [CUML] [warning] Warning: could not fill working set, found only 804 elements\n",
            "[2025-05-27 12:19:57.565] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:19:57.567] [CUML] [warning] Warning: could not fill working set, found only 814 elements\n",
            "[2025-05-27 12:19:57.568] [CUML] [warning] Warning: could not fill working set, found only 795 elements\n",
            "[2025-05-27 12:19:57.570] [CUML] [warning] Warning: could not fill working set, found only 818 elements\n",
            "[2025-05-27 12:19:57.572] [CUML] [warning] Warning: could not fill working set, found only 795 elements\n",
            "[2025-05-27 12:19:57.714] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:19:57.716] [CUML] [warning] Warning: could not fill working set, found only 808 elements\n",
            "[2025-05-27 12:19:57.717] [CUML] [warning] Warning: could not fill working set, found only 802 elements\n",
            "[2025-05-27 12:19:57.719] [CUML] [warning] Warning: could not fill working set, found only 807 elements\n",
            "[2025-05-27 12:19:57.720] [CUML] [warning] Warning: could not fill working set, found only 809 elements\n",
            "Test accuracy score for Support Vector Classifier with TF-IDF + stylometric features:\n",
            " 0.6622478386167147\n",
            "Classification Report for Support Vector Classifier with TF-IDF + stylometric features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.71      0.45      0.55        38\n",
            "        ENFP       0.70      0.62      0.66       135\n",
            "        ENTJ       0.62      0.33      0.43        46\n",
            "        ENTP       0.62      0.61      0.61       137\n",
            "        ESFJ       1.00      0.22      0.36         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.57      0.22      0.32        18\n",
            "        INFJ       0.67      0.74      0.71       294\n",
            "        INFP       0.65      0.80      0.71       366\n",
            "        INTJ       0.63      0.66      0.64       218\n",
            "        INTP       0.68      0.78      0.73       261\n",
            "        ISFJ       0.75      0.45      0.57        33\n",
            "        ISFP       0.77      0.44      0.56        54\n",
            "        ISTJ       0.79      0.37      0.50        41\n",
            "        ISTP       0.67      0.51      0.58        67\n",
            "\n",
            "    accuracy                           0.66      1735\n",
            "   macro avg       0.61      0.45      0.50      1735\n",
            "weighted avg       0.66      0.66      0.65      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 4: Support Vector Classifier\n",
        "# Use TF-IDF + Stylometric features + Trait Vector\n",
        "model_svc_all = SVC(random_state=42)\n",
        "model_svc_all.fit(train_combined_stylo, train_target)\n",
        "pred_all = model_lgb_all.predict(test_combined_stylo)\n",
        "print(\"Test accuracy score for Support Vector Classifier with TF-IDF + Stylometric + trait vector features:\\n\", accuracy_score(test_target, pred_all))\n",
        "print(\"Classification Report for Support Vector Classifier with TF-IDF + Stylometric + trait vector features:\\n\")\n",
        "print(classification_report(test_target, pred_all, target_names=target_encoder.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV7XRn6Fr-7u",
        "outputId": "cc6cdbcc-a15d-49c8-d5be-7eb831c19895"
      },
      "id": "AV7XRn6Fr-7u",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-05-27 12:22:46.969] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:22:46.972] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 12:22:46.973] [CUML] [warning] Warning: could not fill working set, found only 831 elements\n",
            "[2025-05-27 12:22:46.975] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 12:22:47.068] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:22:47.070] [CUML] [warning] Warning: could not fill working set, found only 865 elements\n",
            "[2025-05-27 12:22:47.072] [CUML] [warning] Warning: could not fill working set, found only 827 elements\n",
            "[2025-05-27 12:22:47.074] [CUML] [warning] Warning: could not fill working set, found only 865 elements\n",
            "[2025-05-27 12:22:47.145] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:22:47.147] [CUML] [warning] Warning: could not fill working set, found only 845 elements\n",
            "[2025-05-27 12:22:47.149] [CUML] [warning] Warning: could not fill working set, found only 843 elements\n",
            "[2025-05-27 12:22:47.151] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:22:47.152] [CUML] [warning] Warning: could not fill working set, found only 837 elements\n",
            "[2025-05-27 12:22:47.230] [CUML] [warning] Warning: could not fill working set, found only 664 elements\n",
            "[2025-05-27 12:22:47.233] [CUML] [warning] Warning: could not fill working set, found only 859 elements\n",
            "[2025-05-27 12:22:47.234] [CUML] [warning] Warning: could not fill working set, found only 831 elements\n",
            "[2025-05-27 12:22:47.236] [CUML] [warning] Warning: could not fill working set, found only 857 elements\n",
            "[2025-05-27 12:22:47.238] [CUML] [warning] Warning: could not fill working set, found only 836 elements\n",
            "[2025-05-27 12:22:47.516] [CUML] [warning] Warning: could not fill working set, found only 832 elements\n",
            "[2025-05-27 12:22:47.518] [CUML] [warning] Warning: could not fill working set, found only 896 elements\n",
            "[2025-05-27 12:22:47.821] [CUML] [warning] Warning: could not fill working set, found only 1016 elements\n",
            "[2025-05-27 12:22:48.621] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:22:48.624] [CUML] [warning] Warning: could not fill working set, found only 878 elements\n",
            "[2025-05-27 12:22:48.625] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:22:48.627] [CUML] [warning] Warning: could not fill working set, found only 878 elements\n",
            "[2025-05-27 12:22:48.628] [CUML] [warning] Warning: could not fill working set, found only 843 elements\n",
            "[2025-05-27 12:22:48.716] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:22:48.718] [CUML] [warning] Warning: could not fill working set, found only 882 elements\n",
            "[2025-05-27 12:22:48.720] [CUML] [warning] Warning: could not fill working set, found only 841 elements\n",
            "[2025-05-27 12:22:48.721] [CUML] [warning] Warning: could not fill working set, found only 886 elements\n",
            "[2025-05-27 12:22:48.785] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:22:48.788] [CUML] [warning] Warning: could not fill working set, found only 875 elements\n",
            "[2025-05-27 12:22:48.789] [CUML] [warning] Warning: could not fill working set, found only 846 elements\n",
            "[2025-05-27 12:22:48.791] [CUML] [warning] Warning: could not fill working set, found only 876 elements\n",
            "[2025-05-27 12:22:48.867] [CUML] [warning] Warning: could not fill working set, found only 697 elements\n",
            "[2025-05-27 12:22:48.870] [CUML] [warning] Warning: could not fill working set, found only 880 elements\n",
            "[2025-05-27 12:22:48.872] [CUML] [warning] Warning: could not fill working set, found only 842 elements\n",
            "[2025-05-27 12:22:48.874] [CUML] [warning] Warning: could not fill working set, found only 879 elements\n",
            "[2025-05-27 12:22:49.992] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:22:49.994] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:22:49.996] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:22:49.997] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:22:49.999] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:22:50.080] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:22:50.082] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:22:50.083] [CUML] [warning] Warning: could not fill working set, found only 780 elements\n",
            "[2025-05-27 12:22:50.085] [CUML] [warning] Warning: could not fill working set, found only 803 elements\n",
            "[2025-05-27 12:22:50.223] [CUML] [warning] Warning: could not fill working set, found only 545 elements\n",
            "[2025-05-27 12:22:50.224] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:22:50.226] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:22:50.228] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:22:50.434] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:22:50.435] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:22:50.437] [CUML] [warning] Warning: could not fill working set, found only 789 elements\n",
            "[2025-05-27 12:22:50.438] [CUML] [warning] Warning: could not fill working set, found only 789 elements\n",
            "[2025-05-27 12:22:50.440] [CUML] [warning] Warning: could not fill working set, found only 789 elements\n",
            "[2025-05-27 12:22:50.518] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:22:50.520] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:22:50.521] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:22:50.523] [CUML] [warning] Warning: could not fill working set, found only 790 elements\n",
            "[2025-05-27 12:22:50.525] [CUML] [warning] Warning: could not fill working set, found only 792 elements\n",
            "[2025-05-27 12:22:50.654] [CUML] [warning] Warning: could not fill working set, found only 550 elements\n",
            "[2025-05-27 12:22:50.656] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:22:50.657] [CUML] [warning] Warning: could not fill working set, found only 792 elements\n",
            "[2025-05-27 12:22:50.659] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:22:50.853] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:22:50.854] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:22:50.856] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:22:50.858] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:22:50.859] [CUML] [warning] Warning: could not fill working set, found only 793 elements\n",
            "[2025-05-27 12:22:50.940] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:22:50.942] [CUML] [warning] Warning: could not fill working set, found only 786 elements\n",
            "[2025-05-27 12:22:50.943] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:22:50.945] [CUML] [warning] Warning: could not fill working set, found only 788 elements\n",
            "[2025-05-27 12:22:50.946] [CUML] [warning] Warning: could not fill working set, found only 783 elements\n",
            "[2025-05-27 12:22:51.077] [CUML] [warning] Warning: could not fill working set, found only 543 elements\n",
            "[2025-05-27 12:22:51.079] [CUML] [warning] Warning: could not fill working set, found only 782 elements\n",
            "[2025-05-27 12:22:51.081] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:22:51.082] [CUML] [warning] Warning: could not fill working set, found only 784 elements\n",
            "[2025-05-27 12:22:51.084] [CUML] [warning] Warning: could not fill working set, found only 787 elements\n",
            "[2025-05-27 12:22:51.256] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:22:51.258] [CUML] [warning] Warning: could not fill working set, found only 805 elements\n",
            "[2025-05-27 12:22:51.259] [CUML] [warning] Warning: could not fill working set, found only 804 elements\n",
            "[2025-05-27 12:22:51.261] [CUML] [warning] Warning: could not fill working set, found only 805 elements\n",
            "[2025-05-27 12:22:51.263] [CUML] [warning] Warning: could not fill working set, found only 804 elements\n",
            "[2025-05-27 12:22:51.346] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:22:51.348] [CUML] [warning] Warning: could not fill working set, found only 814 elements\n",
            "[2025-05-27 12:22:51.349] [CUML] [warning] Warning: could not fill working set, found only 795 elements\n",
            "[2025-05-27 12:22:51.351] [CUML] [warning] Warning: could not fill working set, found only 819 elements\n",
            "[2025-05-27 12:22:51.352] [CUML] [warning] Warning: could not fill working set, found only 796 elements\n",
            "[2025-05-27 12:22:51.480] [CUML] [warning] Warning: could not fill working set, found only 583 elements\n",
            "[2025-05-27 12:22:51.482] [CUML] [warning] Warning: could not fill working set, found only 808 elements\n",
            "[2025-05-27 12:22:51.483] [CUML] [warning] Warning: could not fill working set, found only 802 elements\n",
            "[2025-05-27 12:22:51.485] [CUML] [warning] Warning: could not fill working set, found only 807 elements\n",
            "[2025-05-27 12:22:51.487] [CUML] [warning] Warning: could not fill working set, found only 809 elements\n",
            "Test accuracy score for Support Vector Classifier with TF-IDF + Stylometric + trait vector features:\n",
            " 0.6680115273775216\n",
            "Classification Report for Support Vector Classifier with TF-IDF + Stylometric + trait vector features:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ENFJ       0.71      0.39      0.51        38\n",
            "        ENFP       0.67      0.61      0.64       135\n",
            "        ENTJ       0.73      0.35      0.47        46\n",
            "        ENTP       0.66      0.63      0.64       137\n",
            "        ESFJ       1.00      0.22      0.36         9\n",
            "        ESFP       0.00      0.00      0.00        10\n",
            "        ESTJ       0.00      0.00      0.00         8\n",
            "        ESTP       0.60      0.17      0.26        18\n",
            "        INFJ       0.68      0.77      0.72       294\n",
            "        INFP       0.65      0.81      0.72       366\n",
            "        INTJ       0.62      0.64      0.63       218\n",
            "        INTP       0.69      0.79      0.73       261\n",
            "        ISFJ       0.76      0.39      0.52        33\n",
            "        ISFP       0.75      0.44      0.56        54\n",
            "        ISTJ       0.76      0.39      0.52        41\n",
            "        ISTP       0.67      0.54      0.60        67\n",
            "\n",
            "    accuracy                           0.67      1735\n",
            "   macro avg       0.62      0.45      0.49      1735\n",
            "weighted avg       0.67      0.67      0.66      1735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}